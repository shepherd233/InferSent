{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>第四章 动态规划法</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 基于状态值函数的策略评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;根据状态值函数的贝尔曼方程，可以通过联立线性方程组的方法，求解得每个状态在对应策略$\\pi$下的状态。针对在状态$[i, j]$的扫地机器人，我们可以列出如下的贝尔曼方程：<br>\n",
    "<center>$v_\\pi(S_{ij})=\\sum\\pi(a|S_{ij})p(S_{ij},a,s')(r(S_{ij},a)+\\gamma v_\\pi(s'))$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;通常可以采取以下两种方式提前结束迭代：<br>\n",
    "（1）直接设置迭代次数。只要达到预期的迭代次数，即可停止迭代；<br>\n",
    "（2）设定较小的阈值（次优界限）$\\theta$。当$|v_\\iota(s)-v_(\\iota-1)(s)|<\\theta$时，停止迭代。比较两次迭代的状态值函数差的绝对值$\\Delta$（或差的平方），当$\\Delta$最大值小于阈值时，终止迭代。\n",
    "下面使用的是第二种方法。<br><br>\n",
    "\n",
    "\n",
    "&emsp;&emsp;迭代方法：<br>\n",
    "（1）异步：即在相邻的两个迭代轮次$\\iota$和$\\iota-1$，保存同一组状态值函数$V(s)$。在$V(s)$中，存储两轮混合的函数值。因此在每次计算中，如果状态$s$的值函数已被更新，那么当用到$V(s)$时，就使用已经更新过的数据。评估过程中，中间结果与状态评估的先后此序密切相关。<br>\n",
    "<center><img src='./第四章图片/图4.1.png' width='600'></center>\n",
    "<center>算法4.1使用的迭代方法是异步计算方式</center>\n",
    "\n",
    "（2）同步：即每一迭代轮次$\\iota$，都保存相邻两轮的状态值函数：$V_\\iota(s)$和$V_{\\iota-1}(s)$。在计算$V_\\iota(s)$过程中，使用的全部是上一轮的$V_{\\iota-1}(s)$值。评估过程中，中间结果与状态评估的先后次序无关。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**例4.1** 设定策略评估的起始位置为左下角（如下图所示），即充电桩位置，按序号顺序进行评估。<br>\n",
    "&emsp;&emsp;机器人在非终止状态（除位置 0、12、19）均采取等概率策略$\\pi(a|s)=1/|A(s)|$，$|A(s)|$为当前状态$s$可采取的动作个数。扫地机器人最多可以采取{Up,Down,Left,Right}4个动作。到达充电桩位置时，r= +1；到达垃圾位置时， r=+3；撞到障碍物时，r=−10；其他情况，获得的奖赏 r 均为0。折扣系数$\\gamma$=0.8，利用算法4.1计算，在策略$\\pi$下，确定环境扫地机器人任务的状态值函数。\n",
    "<center><img src='./第四章图片/图4.2.png' width='200'></center>\n",
    "<center>图4.1 扫地机器人环境</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算过程如下：<br>\n",
    "（1）当$\\iota=0$时，对所有的$s$初始化为：$V(s)=0$<br>\n",
    "（2）当$\\iota=1$时，以状态$S_{5}$、$S_{17}$、$S_{24}$为例：\n",
    "<center>\n",
    "    <img src='./第四章图片/图4.3.png' width='600'>\n",
    "    <img src='./第四章图片/图4.4.png' width='600'>\n",
    "    <img src='./第四章图片/图4.5.png' width='600'></center><br>\n",
    "按顺序计算完一轮后，得到值函数$V(s)$<br>\n",
    "（3）当$\\iota=2$时，以状态$S_{5}$、$S_{17}$、$S_{24}$为例。采用<b>异步</b>计算方式：\n",
    "<center><img src='./第四章图片/图4.6.png' width='600'></center><br>\n",
    "（4）当$\\iota=30$时，$|V_\\iota(s)-V_{\\iota-1}(s)|<\\Delta$，认为$V_\\iota(s)$已经收敛于$v_\\pi(s)$，计算得到的$v_\\pi(s)$就是在策略$\\pi$下的有效评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随着迭代的进行，每轮状态值函数的更新过程如下：\n",
    "<center><img src='./第四章图片/图4.7.png'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1 的状态 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*0.000)+ 0.00*(0+0.8*0.000)+ 0.33*(1+0.8*0.000)+v = 0.333\n",
      "第2 的状态 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*0.000)+ 0.00*(0+0.8*0.000)+ 0.33*(0+0.8*0.333)+v = 0.089\n",
      "第3 的状态 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*0.000)+ 0.00*(0+0.8*0.000)+ 0.33*(0+0.8*0.089)+v = 0.024\n",
      "第4 的状态 0.50*(0+0.8*0.000)+ 0.00*(0+0.8*0.000)+ 0.00*(0+0.8*0.000)+ 0.50*(0+0.8*0.024)+v = 0.009\n",
      "第5 的状态 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*0.000)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*0.000)+v = 0.333\n",
      "第6 的状态 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*0.333)+ 0.25*(0+0.8*0.333)+v = 0.133\n",
      "第7 的状态 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*0.089)+ 0.25*(0+0.8*0.133)+v = -2.456\n",
      "第8 的状态 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*0.024)+ 0.25*(0+0.8*-2.456)+v = -0.486\n",
      "第9 的状态 0.33*(0+0.8*0.000)+ 0.00*(0+0.8*0.000)+ 0.33*(0+0.8*0.009)+ 0.33*(0+0.8*-0.486)+v = -0.127\n",
      "第10 的状态 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*0.333)+ 0.00*(0+0.8*0.000)+v = 0.089\n",
      "第11 的状态 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*0.133)+ 0.25*(0+0.8*0.089)+v = -2.456\n",
      "第13 的状态 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*-0.486)+v = -2.597\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*0.000)+ 0.33*(0+0.8*-0.127)+ 0.33*(0+0.8*-2.597)+v = 0.273\n",
      "第15 的状态 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*0.089)+ 0.00*(0+0.8*0.000)+v = 0.024\n",
      "第16 的状态 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*-2.456)+ 0.25*(0+0.8*0.024)+v = -0.486\n",
      "第17 的状态 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*0.000)+ 0.25*(0+0.8*-0.486)+v = -2.597\n",
      "第18 的状态 0.25*(0+0.8*0.000)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-2.597)+ 0.25*(0+0.8*-2.597)+v = -0.289\n",
      "第20 的状态 0.00*(0+0.8*0.000)+ 0.50*(0+0.8*0.000)+ 0.50*(0+0.8*0.024)+ 0.00*(0+0.8*0.000)+v = 0.009\n",
      "第21 的状态 0.00*(0+0.8*0.000)+ 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*-0.486)+ 0.33*(0+0.8*0.009)+v = -0.127\n",
      "第22 的状态 0.00*(0+0.8*0.000)+ 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*-2.597)+ 0.33*(0+0.8*-0.127)+v = -0.727\n",
      "第23 的状态 0.00*(0+0.8*0.000)+ 0.33*(0+0.8*0.000)+ 0.33*(0+0.8*-0.289)+ 0.33*(0+0.8*-0.727)+v = -0.271\n",
      "第24 的状态 0.00*(0+0.8*0.000)+ 0.00*(0+0.8*0.000)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.271)+v = 1.392\n",
      "k= 1\n",
      "[[ 0.0095 -0.1272 -0.7265 -0.2708  1.3917]\n",
      " [ 0.0237 -0.4864 -2.5973 -0.2889  0.    ]\n",
      " [ 0.0889 -2.4556  0.     -2.5973  0.2735]\n",
      " [ 0.3333  0.1333 -2.4556 -0.4864 -0.1272]\n",
      " [ 0.      0.3333  0.0889  0.0237  0.0095]]\n",
      "第1 的状态 0.33*(0+0.8*0.133)+ 0.33*(0+0.8*0.089)+ 0.00*(0+0.8*0.333)+ 0.33*(1+0.8*0.000)+v = 0.393\n",
      "第2 的状态 0.33*(0+0.8*-2.456)+ 0.33*(0+0.8*0.024)+ 0.00*(0+0.8*0.089)+ 0.33*(0+0.8*0.393)+v = -0.544\n",
      "第3 的状态 0.33*(0+0.8*-0.486)+ 0.33*(0+0.8*0.009)+ 0.00*(0+0.8*0.024)+ 0.33*(0+0.8*-0.544)+v = -0.272\n",
      "第4 的状态 0.50*(0+0.8*-0.127)+ 0.00*(0+0.8*0.009)+ 0.00*(0+0.8*0.009)+ 0.50*(0+0.8*-0.272)+v = -0.160\n",
      "第5 的状态 0.33*(0+0.8*0.089)+ 0.33*(0+0.8*0.133)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*0.333)+v = 0.393\n",
      "第6 的状态 0.25*(0+0.8*-2.456)+ 0.25*(0+0.8*-2.456)+ 0.25*(0+0.8*0.393)+ 0.25*(0+0.8*0.393)+v = -0.825\n",
      "第7 的状态 0.25*(0+0.8*-0.486)+ 0.25*(0+0.8*-0.544)+ 0.25*(0+0.8*-0.825)+v = -3.362\n",
      "第8 的状态 0.25*(0+0.8*-2.597)+ 0.25*(0+0.8*-0.127)+ 0.25*(0+0.8*-0.272)+ 0.25*(0+0.8*-3.362)+v = -1.272\n",
      "第9 的状态 0.33*(0+0.8*0.273)+ 0.00*(0+0.8*-0.127)+ 0.33*(0+0.8*-0.160)+ 0.33*(0+0.8*-1.272)+v = -0.309\n",
      "第10 的状态 0.33*(0+0.8*0.024)+ 0.33*(0+0.8*-2.456)+ 0.33*(0+0.8*0.393)+ 0.00*(0+0.8*0.089)+v = -0.544\n",
      "第11 的状态 0.25*(0+0.8*-0.486)+ 0.25*(0+0.8*-0.825)+ 0.25*(0+0.8*-0.544)+v = -3.362\n",
      "第13 的状态 0.25*(0+0.8*-0.289)+ 0.25*(0+0.8*0.273)+ 0.25*(0+0.8*-1.272)+v = -3.277\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*0.273)+ 0.33*(0+0.8*-0.309)+ 0.33*(0+0.8*-3.277)+v = 0.044\n",
      "第15 的状态 0.33*(0+0.8*0.009)+ 0.33*(0+0.8*-0.486)+ 0.33*(0+0.8*-0.544)+ 0.00*(0+0.8*0.024)+v = -0.272\n",
      "第16 的状态 0.25*(0+0.8*-0.127)+ 0.25*(0+0.8*-2.597)+ 0.25*(0+0.8*-3.362)+ 0.25*(0+0.8*-0.272)+v = -1.272\n",
      "第17 的状态 0.25*(0+0.8*-0.727)+ 0.25*(0+0.8*-0.289)+ 0.25*(0+0.8*-1.272)+v = -3.477\n",
      "第18 的状态 0.25*(0+0.8*-0.271)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.277)+ 0.25*(0+0.8*-3.477)+v = -0.655\n",
      "第20 的状态 0.00*(0+0.8*0.009)+ 0.50*(0+0.8*-0.127)+ 0.50*(0+0.8*-0.272)+ 0.00*(0+0.8*0.009)+v = -0.160\n",
      "第21 的状态 0.00*(0+0.8*-0.127)+ 0.33*(0+0.8*-0.727)+ 0.33*(0+0.8*-1.272)+ 0.33*(0+0.8*-0.160)+v = -0.575\n",
      "第22 的状态 0.00*(0+0.8*-0.727)+ 0.33*(0+0.8*-0.271)+ 0.33*(0+0.8*-3.477)+ 0.33*(0+0.8*-0.575)+v = -1.153\n",
      "第23 的状态 0.00*(0+0.8*-0.271)+ 0.33*(0+0.8*1.392)+ 0.33*(0+0.8*-0.655)+ 0.33*(0+0.8*-1.153)+v = -0.111\n",
      "第24 的状态 0.00*(0+0.8*1.392)+ 0.00*(0+0.8*1.392)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.111)+v = 1.456\n",
      "k= 2\n",
      "[[-0.1597 -0.5755 -1.1528 -0.111   1.4556]\n",
      " [-0.2722 -1.2718 -3.4769 -0.6549  0.    ]\n",
      " [-0.5438 -3.3622  0.     -3.2769  0.0438]\n",
      " [ 0.3926 -0.8252 -3.3622 -1.2718 -0.3088]\n",
      " [ 0.      0.3926 -0.5438 -0.2722 -0.1597]]\n",
      "第1 的状态 0.33*(0+0.8*-0.825)+ 0.33*(0+0.8*-0.544)+ 0.00*(0+0.8*0.393)+ 0.33*(1+0.8*0.000)+v = -0.032\n",
      "第2 的状态 0.33*(0+0.8*-3.362)+ 0.33*(0+0.8*-0.272)+ 0.00*(0+0.8*-0.544)+ 0.33*(0+0.8*-0.032)+v = -0.978\n",
      "第3 的状态 0.33*(0+0.8*-1.272)+ 0.33*(0+0.8*-0.160)+ 0.00*(0+0.8*-0.272)+ 0.33*(0+0.8*-0.978)+v = -0.642\n",
      "第4 的状态 0.50*(0+0.8*-0.309)+ 0.00*(0+0.8*-0.160)+ 0.00*(0+0.8*-0.160)+ 0.50*(0+0.8*-0.642)+v = -0.380\n",
      "第5 的状态 0.33*(0+0.8*-0.544)+ 0.33*(0+0.8*-0.825)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*0.393)+v = -0.032\n",
      "第6 的状态 0.25*(0+0.8*-3.362)+ 0.25*(0+0.8*-3.362)+ 0.25*(0+0.8*-0.032)+ 0.25*(0+0.8*-0.032)+v = -1.358\n",
      "第7 的状态 0.25*(0+0.8*-1.272)+ 0.25*(0+0.8*-0.978)+ 0.25*(0+0.8*-1.358)+v = -3.894\n",
      "第8 的状态 0.25*(0+0.8*-3.277)+ 0.25*(0+0.8*-0.309)+ 0.25*(0+0.8*-0.642)+ 0.25*(0+0.8*-3.894)+v = -1.624\n",
      "第9 的状态 0.33*(0+0.8*0.044)+ 0.00*(0+0.8*-0.309)+ 0.33*(0+0.8*-0.380)+ 0.33*(0+0.8*-1.624)+v = -0.523\n",
      "第10 的状态 0.33*(0+0.8*-0.272)+ 0.33*(0+0.8*-3.362)+ 0.33*(0+0.8*-0.032)+ 0.00*(0+0.8*-0.544)+v = -0.978\n",
      "第11 的状态 0.25*(0+0.8*-1.272)+ 0.25*(0+0.8*-1.358)+ 0.25*(0+0.8*-0.978)+v = -3.894\n",
      "第13 的状态 0.25*(0+0.8*-0.655)+ 0.25*(0+0.8*0.044)+ 0.25*(0+0.8*-1.624)+v = -3.602\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*0.044)+ 0.33*(0+0.8*-0.523)+ 0.33*(0+0.8*-3.602)+v = -0.100\n",
      "第15 的状态 0.33*(0+0.8*-0.160)+ 0.33*(0+0.8*-1.272)+ 0.33*(0+0.8*-0.978)+ 0.00*(0+0.8*-0.272)+v = -0.642\n",
      "第16 的状态 0.25*(0+0.8*-0.575)+ 0.25*(0+0.8*-3.477)+ 0.25*(0+0.8*-3.894)+ 0.25*(0+0.8*-0.642)+v = -1.718\n",
      "第17 的状态 0.25*(0+0.8*-1.153)+ 0.25*(0+0.8*-0.655)+ 0.25*(0+0.8*-1.718)+v = -3.900\n",
      "第18 的状态 0.25*(0+0.8*-0.111)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.602)+ 0.25*(0+0.8*-3.900)+v = -0.773\n",
      "第20 的状态 0.00*(0+0.8*-0.160)+ 0.50*(0+0.8*-0.575)+ 0.50*(0+0.8*-0.642)+ 0.00*(0+0.8*-0.160)+v = -0.487\n",
      "第21 的状态 0.00*(0+0.8*-0.575)+ 0.33*(0+0.8*-1.153)+ 0.33*(0+0.8*-1.718)+ 0.33*(0+0.8*-0.487)+v = -0.895\n",
      "第22 的状态 0.00*(0+0.8*-1.153)+ 0.33*(0+0.8*-0.111)+ 0.33*(0+0.8*-3.900)+ 0.33*(0+0.8*-0.895)+v = -1.308\n",
      "第23 的状态 0.00*(0+0.8*-0.111)+ 0.33*(0+0.8*1.456)+ 0.33*(0+0.8*-0.773)+ 0.33*(0+0.8*-1.308)+v = -0.167\n",
      "第24 的状态 0.00*(0+0.8*1.456)+ 0.00*(0+0.8*1.456)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.167)+v = 1.433\n",
      "k= 3\n",
      "[[-0.4872 -0.8954 -1.3085 -0.1668  1.4333]\n",
      " [-0.6424 -1.7177 -3.9005 -0.7728  0.    ]\n",
      " [-0.9776 -3.8938  0.     -3.6025 -0.1001]\n",
      " [-0.0317 -1.3576 -3.8938 -1.6244 -0.523 ]\n",
      " [ 0.     -0.0317 -0.9776 -0.6424 -0.3805]]\n",
      "第1 的状态 0.33*(0+0.8*-1.358)+ 0.33*(0+0.8*-0.978)+ 0.00*(0+0.8*-0.032)+ 0.33*(1+0.8*0.000)+v = -0.289\n",
      "第2 的状态 0.33*(0+0.8*-3.894)+ 0.33*(0+0.8*-0.642)+ 0.00*(0+0.8*-0.978)+ 0.33*(0+0.8*-0.289)+v = -1.287\n",
      "第3 的状态 0.33*(0+0.8*-1.624)+ 0.33*(0+0.8*-0.380)+ 0.00*(0+0.8*-0.642)+ 0.33*(0+0.8*-1.287)+v = -0.878\n",
      "第4 的状态 0.50*(0+0.8*-0.523)+ 0.00*(0+0.8*-0.380)+ 0.00*(0+0.8*-0.380)+ 0.50*(0+0.8*-0.878)+v = -0.560\n",
      "第5 的状态 0.33*(0+0.8*-0.978)+ 0.33*(0+0.8*-1.358)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.032)+v = -0.289\n",
      "第6 的状态 0.25*(0+0.8*-3.894)+ 0.25*(0+0.8*-3.894)+ 0.25*(0+0.8*-0.289)+ 0.25*(0+0.8*-0.289)+v = -1.673\n",
      "第7 的状态 0.25*(0+0.8*-1.624)+ 0.25*(0+0.8*-1.287)+ 0.25*(0+0.8*-1.673)+v = -4.196\n",
      "第8 的状态 0.25*(0+0.8*-3.602)+ 0.25*(0+0.8*-0.523)+ 0.25*(0+0.8*-0.878)+ 0.25*(0+0.8*-4.196)+v = -1.840\n",
      "第9 的状态 0.33*(0+0.8*-0.100)+ 0.00*(0+0.8*-0.523)+ 0.33*(0+0.8*-0.560)+ 0.33*(0+0.8*-1.840)+v = -0.667\n",
      "第10 的状态 0.33*(0+0.8*-0.642)+ 0.33*(0+0.8*-3.894)+ 0.33*(0+0.8*-0.289)+ 0.00*(0+0.8*-0.978)+v = -1.287\n",
      "第11 的状态 0.25*(0+0.8*-1.718)+ 0.25*(0+0.8*-1.673)+ 0.25*(0+0.8*-1.287)+v = -4.214\n",
      "第13 的状态 0.25*(0+0.8*-0.773)+ 0.25*(0+0.8*-0.100)+ 0.25*(0+0.8*-1.840)+v = -3.763\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.100)+ 0.33*(0+0.8*-0.667)+ 0.33*(0+0.8*-3.763)+v = -0.181\n",
      "第15 的状态 0.33*(0+0.8*-0.487)+ 0.33*(0+0.8*-1.718)+ 0.33*(0+0.8*-1.287)+ 0.00*(0+0.8*-0.642)+v = -0.931\n",
      "第16 的状态 0.25*(0+0.8*-0.895)+ 0.25*(0+0.8*-3.900)+ 0.25*(0+0.8*-4.214)+ 0.25*(0+0.8*-0.931)+v = -1.988\n",
      "第17 的状态 0.25*(0+0.8*-1.308)+ 0.25*(0+0.8*-0.773)+ 0.25*(0+0.8*-1.988)+v = -4.094\n",
      "第18 的状态 0.25*(0+0.8*-0.167)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.763)+ 0.25*(0+0.8*-4.094)+v = -0.855\n",
      "第20 的状态 0.00*(0+0.8*-0.487)+ 0.50*(0+0.8*-0.895)+ 0.50*(0+0.8*-0.931)+ 0.00*(0+0.8*-0.487)+v = -0.731\n",
      "第21 的状态 0.00*(0+0.8*-0.895)+ 0.33*(0+0.8*-1.308)+ 0.33*(0+0.8*-1.988)+ 0.33*(0+0.8*-0.731)+v = -1.074\n",
      "第22 的状态 0.00*(0+0.8*-1.308)+ 0.33*(0+0.8*-0.167)+ 0.33*(0+0.8*-4.094)+ 0.33*(0+0.8*-1.074)+v = -1.423\n",
      "第23 的状态 0.00*(0+0.8*-0.167)+ 0.33*(0+0.8*1.433)+ 0.33*(0+0.8*-0.855)+ 0.33*(0+0.8*-1.423)+v = -0.225\n",
      "第24 的状态 0.00*(0+0.8*1.433)+ 0.00*(0+0.8*1.433)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.225)+v = 1.410\n",
      "k= 4\n",
      "[[-0.7306 -1.074  -1.4226 -0.2251  1.41  ]\n",
      " [-0.9311 -1.9883 -4.094  -0.8548  0.    ]\n",
      " [-1.2868 -4.2143  0.     -3.763  -0.1813]\n",
      " [-0.2894 -1.6733 -4.1957 -1.8398 -0.6667]\n",
      " [ 0.     -0.2894 -1.2868 -0.8778 -0.5603]]\n",
      "第1 的状态 0.33*(0+0.8*-1.673)+ 0.33*(0+0.8*-1.287)+ 0.00*(0+0.8*-0.289)+ 0.33*(1+0.8*0.000)+v = -0.456\n",
      "第2 的状态 0.33*(0+0.8*-4.196)+ 0.33*(0+0.8*-0.878)+ 0.00*(0+0.8*-1.287)+ 0.33*(0+0.8*-0.456)+v = -1.475\n",
      "第3 的状态 0.33*(0+0.8*-1.840)+ 0.33*(0+0.8*-0.560)+ 0.00*(0+0.8*-0.878)+ 0.33*(0+0.8*-1.475)+v = -1.033\n",
      "第4 的状态 0.50*(0+0.8*-0.667)+ 0.00*(0+0.8*-0.560)+ 0.00*(0+0.8*-0.560)+ 0.50*(0+0.8*-1.033)+v = -0.680\n",
      "第5 的状态 0.33*(0+0.8*-1.287)+ 0.33*(0+0.8*-1.673)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.289)+v = -0.456\n",
      "第6 的状态 0.25*(0+0.8*-4.214)+ 0.25*(0+0.8*-4.196)+ 0.25*(0+0.8*-0.456)+ 0.25*(0+0.8*-0.456)+v = -1.864\n",
      "第7 的状态 0.25*(0+0.8*-1.840)+ 0.25*(0+0.8*-1.475)+ 0.25*(0+0.8*-1.864)+v = -4.375\n",
      "第8 的状态 0.25*(0+0.8*-3.763)+ 0.25*(0+0.8*-0.667)+ 0.25*(0+0.8*-1.033)+ 0.25*(0+0.8*-4.375)+v = -1.968\n",
      "第9 的状态 0.33*(0+0.8*-0.181)+ 0.00*(0+0.8*-0.667)+ 0.33*(0+0.8*-0.680)+ 0.33*(0+0.8*-1.968)+v = -0.754\n",
      "第10 的状态 0.33*(0+0.8*-0.931)+ 0.33*(0+0.8*-4.214)+ 0.33*(0+0.8*-0.456)+ 0.00*(0+0.8*-1.287)+v = -1.494\n",
      "第11 的状态 0.25*(0+0.8*-1.988)+ 0.25*(0+0.8*-1.864)+ 0.25*(0+0.8*-1.494)+v = -4.412\n",
      "第13 的状态 0.25*(0+0.8*-0.855)+ 0.25*(0+0.8*-0.181)+ 0.25*(0+0.8*-1.968)+v = -3.853\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.181)+ 0.33*(0+0.8*-0.754)+ 0.33*(0+0.8*-3.853)+v = -0.229\n",
      "第15 的状态 0.33*(0+0.8*-0.731)+ 0.33*(0+0.8*-1.988)+ 0.33*(0+0.8*-1.494)+ 0.00*(0+0.8*-0.931)+v = -1.123\n",
      "第16 的状态 0.25*(0+0.8*-1.074)+ 0.25*(0+0.8*-4.094)+ 0.25*(0+0.8*-4.412)+ 0.25*(0+0.8*-1.123)+v = -2.141\n",
      "第17 的状态 0.25*(0+0.8*-1.423)+ 0.25*(0+0.8*-0.855)+ 0.25*(0+0.8*-2.141)+v = -4.202\n",
      "第18 的状态 0.25*(0+0.8*-0.225)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.853)+ 0.25*(0+0.8*-4.202)+v = -0.906\n",
      "第20 的状态 0.00*(0+0.8*-0.731)+ 0.50*(0+0.8*-1.074)+ 0.50*(0+0.8*-1.123)+ 0.00*(0+0.8*-0.731)+v = -0.879\n",
      "第21 的状态 0.00*(0+0.8*-1.074)+ 0.33*(0+0.8*-1.423)+ 0.33*(0+0.8*-2.141)+ 0.33*(0+0.8*-0.879)+v = -1.185\n",
      "第22 的状态 0.00*(0+0.8*-1.423)+ 0.33*(0+0.8*-0.225)+ 0.33*(0+0.8*-4.202)+ 0.33*(0+0.8*-1.185)+v = -1.497\n",
      "第23 的状态 0.00*(0+0.8*-0.225)+ 0.33*(0+0.8*1.410)+ 0.33*(0+0.8*-0.906)+ 0.33*(0+0.8*-1.497)+v = -0.265\n",
      "第24 的状态 0.00*(0+0.8*1.410)+ 0.00*(0+0.8*1.410)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.265)+v = 1.394\n",
      "k= 5\n",
      "[[-0.8789 -1.1846 -1.4966 -0.2647  1.3941]\n",
      " [-1.1234 -2.1407 -4.2024 -0.9062  0.    ]\n",
      " [-1.4937 -4.4121  0.     -3.8533 -0.2287]\n",
      " [-0.456  -1.8644 -4.3749 -1.9676 -0.7544]\n",
      " [ 0.     -0.456  -1.4745 -1.0332 -0.68  ]]\n",
      "第1 的状态 0.33*(0+0.8*-1.864)+ 0.33*(0+0.8*-1.475)+ 0.00*(0+0.8*-0.456)+ 0.33*(1+0.8*0.000)+v = -0.557\n",
      "第2 的状态 0.33*(0+0.8*-4.375)+ 0.33*(0+0.8*-1.033)+ 0.00*(0+0.8*-1.475)+ 0.33*(0+0.8*-0.557)+v = -1.591\n",
      "第3 的状态 0.33*(0+0.8*-1.968)+ 0.33*(0+0.8*-0.680)+ 0.00*(0+0.8*-1.033)+ 0.33*(0+0.8*-1.591)+v = -1.130\n",
      "第4 的状态 0.50*(0+0.8*-0.754)+ 0.00*(0+0.8*-0.680)+ 0.00*(0+0.8*-0.680)+ 0.50*(0+0.8*-1.130)+v = -0.754\n",
      "第5 的状态 0.33*(0+0.8*-1.494)+ 0.33*(0+0.8*-1.864)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.456)+v = -0.562\n",
      "第6 的状态 0.25*(0+0.8*-4.412)+ 0.25*(0+0.8*-4.375)+ 0.25*(0+0.8*-0.557)+ 0.25*(0+0.8*-0.562)+v = -1.981\n",
      "第7 的状态 0.25*(0+0.8*-1.968)+ 0.25*(0+0.8*-1.591)+ 0.25*(0+0.8*-1.981)+v = -4.483\n",
      "第8 的状态 0.25*(0+0.8*-3.853)+ 0.25*(0+0.8*-0.754)+ 0.25*(0+0.8*-1.130)+ 0.25*(0+0.8*-4.483)+v = -2.044\n",
      "第9 的状态 0.33*(0+0.8*-0.229)+ 0.00*(0+0.8*-0.754)+ 0.33*(0+0.8*-0.754)+ 0.33*(0+0.8*-2.044)+v = -0.807\n",
      "第10 的状态 0.33*(0+0.8*-1.123)+ 0.33*(0+0.8*-4.412)+ 0.33*(0+0.8*-0.562)+ 0.00*(0+0.8*-1.494)+v = -1.626\n",
      "第11 的状态 0.25*(0+0.8*-2.141)+ 0.25*(0+0.8*-1.981)+ 0.25*(0+0.8*-1.626)+v = -4.532\n",
      "第13 的状态 0.25*(0+0.8*-0.906)+ 0.25*(0+0.8*-0.229)+ 0.25*(0+0.8*-2.044)+v = -3.906\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.229)+ 0.33*(0+0.8*-0.807)+ 0.33*(0+0.8*-3.906)+v = -0.257\n",
      "第15 的状态 0.33*(0+0.8*-0.879)+ 0.33*(0+0.8*-2.141)+ 0.33*(0+0.8*-1.626)+ 0.00*(0+0.8*-1.123)+v = -1.239\n",
      "第16 的状态 0.25*(0+0.8*-1.185)+ 0.25*(0+0.8*-4.202)+ 0.25*(0+0.8*-4.532)+ 0.25*(0+0.8*-1.239)+v = -2.232\n",
      "第17 的状态 0.25*(0+0.8*-1.497)+ 0.25*(0+0.8*-0.906)+ 0.25*(0+0.8*-2.232)+v = -4.267\n",
      "第18 的状态 0.25*(0+0.8*-0.265)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.906)+ 0.25*(0+0.8*-4.267)+v = -0.938\n",
      "第20 的状态 0.00*(0+0.8*-0.879)+ 0.50*(0+0.8*-1.185)+ 0.50*(0+0.8*-1.239)+ 0.00*(0+0.8*-0.879)+v = -0.969\n",
      "第21 的状态 0.00*(0+0.8*-1.185)+ 0.33*(0+0.8*-1.497)+ 0.33*(0+0.8*-2.232)+ 0.33*(0+0.8*-0.969)+v = -1.253\n",
      "第22 的状态 0.00*(0+0.8*-1.497)+ 0.33*(0+0.8*-0.265)+ 0.33*(0+0.8*-4.267)+ 0.33*(0+0.8*-1.253)+v = -1.543\n",
      "第23 的状态 0.00*(0+0.8*-0.265)+ 0.33*(0+0.8*1.394)+ 0.33*(0+0.8*-0.938)+ 0.33*(0+0.8*-1.543)+v = -0.290\n",
      "第24 的状态 0.00*(0+0.8*1.394)+ 0.00*(0+0.8*1.394)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.290)+v = 1.384\n",
      "k= 6\n",
      "[[-0.9694 -1.2527 -1.5426 -0.2897  1.3841]\n",
      " [-1.2388 -2.2316 -4.2673 -0.9377  0.    ]\n",
      " [-1.626  -4.532   0.     -3.9065 -0.257 ]\n",
      " [-0.5622 -1.9813 -4.4829 -2.0442 -0.8071]\n",
      " [ 0.     -0.5571 -1.5907 -1.1302 -0.7538]]\n",
      "第1 的状态 0.33*(0+0.8*-1.981)+ 0.33*(0+0.8*-1.591)+ 0.00*(0+0.8*-0.557)+ 0.33*(1+0.8*0.000)+v = -0.619\n",
      "第2 的状态 0.33*(0+0.8*-4.483)+ 0.33*(0+0.8*-1.130)+ 0.00*(0+0.8*-1.591)+ 0.33*(0+0.8*-0.619)+v = -1.662\n",
      "第3 的状态 0.33*(0+0.8*-2.044)+ 0.33*(0+0.8*-0.754)+ 0.00*(0+0.8*-1.130)+ 0.33*(0+0.8*-1.662)+v = -1.189\n",
      "第4 的状态 0.50*(0+0.8*-0.807)+ 0.00*(0+0.8*-0.754)+ 0.00*(0+0.8*-0.754)+ 0.50*(0+0.8*-1.189)+v = -0.799\n",
      "第5 的状态 0.33*(0+0.8*-1.626)+ 0.33*(0+0.8*-1.981)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.562)+v = -0.629\n",
      "第6 的状态 0.25*(0+0.8*-4.532)+ 0.25*(0+0.8*-4.483)+ 0.25*(0+0.8*-0.619)+ 0.25*(0+0.8*-0.629)+v = -2.053\n",
      "第7 的状态 0.25*(0+0.8*-2.044)+ 0.25*(0+0.8*-1.662)+ 0.25*(0+0.8*-2.053)+v = -4.548\n",
      "第8 的状态 0.25*(0+0.8*-3.906)+ 0.25*(0+0.8*-0.807)+ 0.25*(0+0.8*-1.189)+ 0.25*(0+0.8*-4.548)+v = -2.090\n",
      "第9 的状态 0.33*(0+0.8*-0.257)+ 0.00*(0+0.8*-0.807)+ 0.33*(0+0.8*-0.799)+ 0.33*(0+0.8*-2.090)+v = -0.839\n",
      "第10 的状态 0.33*(0+0.8*-1.239)+ 0.33*(0+0.8*-4.532)+ 0.33*(0+0.8*-0.629)+ 0.00*(0+0.8*-1.626)+v = -1.707\n",
      "第11 的状态 0.25*(0+0.8*-2.232)+ 0.25*(0+0.8*-2.053)+ 0.25*(0+0.8*-1.707)+v = -4.605\n",
      "第13 的状态 0.25*(0+0.8*-0.938)+ 0.25*(0+0.8*-0.257)+ 0.25*(0+0.8*-2.090)+v = -3.938\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.257)+ 0.33*(0+0.8*-0.839)+ 0.33*(0+0.8*-3.938)+v = -0.274\n",
      "第15 的状态 0.33*(0+0.8*-0.969)+ 0.33*(0+0.8*-2.232)+ 0.33*(0+0.8*-1.707)+ 0.00*(0+0.8*-1.239)+v = -1.309\n",
      "第16 的状态 0.25*(0+0.8*-1.253)+ 0.25*(0+0.8*-4.267)+ 0.25*(0+0.8*-4.605)+ 0.25*(0+0.8*-1.309)+v = -2.287\n",
      "第17 的状态 0.25*(0+0.8*-1.543)+ 0.25*(0+0.8*-0.938)+ 0.25*(0+0.8*-2.287)+v = -4.307\n",
      "第18 的状态 0.25*(0+0.8*-0.290)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.938)+ 0.25*(0+0.8*-4.307)+v = -0.957\n",
      "第20 的状态 0.00*(0+0.8*-0.969)+ 0.50*(0+0.8*-1.253)+ 0.50*(0+0.8*-1.309)+ 0.00*(0+0.8*-0.969)+v = -1.025\n",
      "第21 的状态 0.00*(0+0.8*-1.253)+ 0.33*(0+0.8*-1.543)+ 0.33*(0+0.8*-2.287)+ 0.33*(0+0.8*-1.025)+v = -1.294\n",
      "第22 的状态 0.00*(0+0.8*-1.543)+ 0.33*(0+0.8*-0.290)+ 0.33*(0+0.8*-4.307)+ 0.33*(0+0.8*-1.294)+v = -1.571\n",
      "第23 的状态 0.00*(0+0.8*-0.290)+ 0.33*(0+0.8*1.384)+ 0.33*(0+0.8*-0.957)+ 0.33*(0+0.8*-1.571)+v = -0.305\n",
      "第24 的状态 0.00*(0+0.8*1.384)+ 0.00*(0+0.8*1.384)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.305)+v = 1.378\n",
      "k= 7\n",
      "[[-1.0245 -1.2943 -1.5709 -0.305   1.378 ]\n",
      " [-1.3087 -2.2866 -4.3069 -0.957   0.    ]\n",
      " [-1.7065 -4.6045  0.     -3.9383 -0.2739]\n",
      " [-0.6286 -2.0525 -4.5483 -2.0902 -0.8389]\n",
      " [ 0.     -0.6192 -1.6619 -1.1893 -0.7986]]\n",
      "第1 的状态 0.33*(0+0.8*-2.053)+ 0.33*(0+0.8*-1.662)+ 0.00*(0+0.8*-0.619)+ 0.33*(1+0.8*0.000)+v = -0.657\n",
      "第2 的状态 0.33*(0+0.8*-4.548)+ 0.33*(0+0.8*-1.189)+ 0.00*(0+0.8*-1.662)+ 0.33*(0+0.8*-0.657)+v = -1.705\n",
      "第3 的状态 0.33*(0+0.8*-2.090)+ 0.33*(0+0.8*-0.799)+ 0.00*(0+0.8*-1.189)+ 0.33*(0+0.8*-1.705)+v = -1.225\n",
      "第4 的状态 0.50*(0+0.8*-0.839)+ 0.00*(0+0.8*-0.799)+ 0.00*(0+0.8*-0.799)+ 0.50*(0+0.8*-1.225)+v = -0.826\n",
      "第5 的状态 0.33*(0+0.8*-1.707)+ 0.33*(0+0.8*-2.053)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.629)+v = -0.669\n",
      "第6 的状态 0.25*(0+0.8*-4.605)+ 0.25*(0+0.8*-4.548)+ 0.25*(0+0.8*-0.657)+ 0.25*(0+0.8*-0.669)+v = -2.096\n",
      "第7 的状态 0.25*(0+0.8*-2.090)+ 0.25*(0+0.8*-1.705)+ 0.25*(0+0.8*-2.096)+v = -4.588\n",
      "第8 的状态 0.25*(0+0.8*-3.938)+ 0.25*(0+0.8*-0.839)+ 0.25*(0+0.8*-1.225)+ 0.25*(0+0.8*-4.588)+v = -2.118\n",
      "第9 的状态 0.33*(0+0.8*-0.274)+ 0.00*(0+0.8*-0.839)+ 0.33*(0+0.8*-0.826)+ 0.33*(0+0.8*-2.118)+v = -0.858\n",
      "第10 的状态 0.33*(0+0.8*-1.309)+ 0.33*(0+0.8*-4.605)+ 0.33*(0+0.8*-0.669)+ 0.00*(0+0.8*-1.707)+v = -1.755\n",
      "第11 的状态 0.25*(0+0.8*-2.287)+ 0.25*(0+0.8*-2.096)+ 0.25*(0+0.8*-1.755)+v = -4.648\n",
      "第13 的状态 0.25*(0+0.8*-0.957)+ 0.25*(0+0.8*-0.274)+ 0.25*(0+0.8*-2.118)+v = -3.957\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.274)+ 0.33*(0+0.8*-0.858)+ 0.33*(0+0.8*-3.957)+v = -0.284\n",
      "第15 的状态 0.33*(0+0.8*-1.025)+ 0.33*(0+0.8*-2.287)+ 0.33*(0+0.8*-1.755)+ 0.00*(0+0.8*-1.309)+v = -1.351\n",
      "第16 的状态 0.25*(0+0.8*-1.294)+ 0.25*(0+0.8*-4.307)+ 0.25*(0+0.8*-4.648)+ 0.25*(0+0.8*-1.351)+v = -2.320\n",
      "第17 的状态 0.25*(0+0.8*-1.571)+ 0.25*(0+0.8*-0.957)+ 0.25*(0+0.8*-2.320)+v = -4.331\n",
      "第18 的状态 0.25*(0+0.8*-0.305)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.957)+ 0.25*(0+0.8*-4.331)+v = -0.969\n",
      "第20 的状态 0.00*(0+0.8*-1.025)+ 0.50*(0+0.8*-1.294)+ 0.50*(0+0.8*-1.351)+ 0.00*(0+0.8*-1.025)+v = -1.058\n",
      "第21 的状态 0.00*(0+0.8*-1.294)+ 0.33*(0+0.8*-1.571)+ 0.33*(0+0.8*-2.320)+ 0.33*(0+0.8*-1.058)+v = -1.320\n",
      "第22 的状态 0.00*(0+0.8*-1.571)+ 0.33*(0+0.8*-0.305)+ 0.33*(0+0.8*-4.331)+ 0.33*(0+0.8*-1.320)+v = -1.588\n",
      "第23 的状态 0.00*(0+0.8*-0.305)+ 0.33*(0+0.8*1.378)+ 0.33*(0+0.8*-0.969)+ 0.33*(0+0.8*-1.588)+v = -0.314\n",
      "第24 的状态 0.00*(0+0.8*1.378)+ 0.00*(0+0.8*1.378)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.314)+v = 1.374\n",
      "k= 8\n",
      "[[-1.0582 -1.3198 -1.5882 -0.3144  1.3743]\n",
      " [-1.3511 -2.3201 -4.331  -0.9687  0.    ]\n",
      " [-1.7553 -4.6485  0.     -3.9574 -0.2841]\n",
      " [-0.6691 -2.0958 -4.5879 -2.118  -0.858 ]\n",
      " [ 0.     -0.6572 -1.7053 -1.2251 -0.8256]]\n",
      "第1 的状态 0.33*(0+0.8*-2.096)+ 0.33*(0+0.8*-1.705)+ 0.00*(0+0.8*-0.657)+ 0.33*(1+0.8*0.000)+v = -0.680\n",
      "第2 的状态 0.33*(0+0.8*-4.588)+ 0.33*(0+0.8*-1.225)+ 0.00*(0+0.8*-1.705)+ 0.33*(0+0.8*-0.680)+v = -1.732\n",
      "第3 的状态 0.33*(0+0.8*-2.118)+ 0.33*(0+0.8*-0.826)+ 0.00*(0+0.8*-1.225)+ 0.33*(0+0.8*-1.732)+v = -1.247\n",
      "第4 的状态 0.50*(0+0.8*-0.858)+ 0.00*(0+0.8*-0.826)+ 0.00*(0+0.8*-0.826)+ 0.50*(0+0.8*-1.247)+v = -0.842\n",
      "第5 的状态 0.33*(0+0.8*-1.755)+ 0.33*(0+0.8*-2.096)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.669)+v = -0.694\n",
      "第6 的状态 0.25*(0+0.8*-4.648)+ 0.25*(0+0.8*-4.588)+ 0.25*(0+0.8*-0.680)+ 0.25*(0+0.8*-0.694)+v = -2.122\n",
      "第7 的状态 0.25*(0+0.8*-2.118)+ 0.25*(0+0.8*-1.732)+ 0.25*(0+0.8*-2.122)+v = -4.612\n",
      "第8 的状态 0.25*(0+0.8*-3.957)+ 0.25*(0+0.8*-0.858)+ 0.25*(0+0.8*-1.247)+ 0.25*(0+0.8*-4.612)+v = -2.135\n",
      "第9 的状态 0.33*(0+0.8*-0.284)+ 0.00*(0+0.8*-0.858)+ 0.33*(0+0.8*-0.842)+ 0.33*(0+0.8*-2.135)+v = -0.870\n",
      "第10 的状态 0.33*(0+0.8*-1.351)+ 0.33*(0+0.8*-4.648)+ 0.33*(0+0.8*-0.694)+ 0.00*(0+0.8*-1.755)+v = -1.785\n",
      "第11 的状态 0.25*(0+0.8*-2.320)+ 0.25*(0+0.8*-2.122)+ 0.25*(0+0.8*-1.785)+v = -4.675\n",
      "第13 的状态 0.25*(0+0.8*-0.969)+ 0.25*(0+0.8*-0.284)+ 0.25*(0+0.8*-2.135)+v = -3.969\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.284)+ 0.33*(0+0.8*-0.870)+ 0.33*(0+0.8*-3.969)+v = -0.290\n",
      "第15 的状态 0.33*(0+0.8*-1.058)+ 0.33*(0+0.8*-2.320)+ 0.33*(0+0.8*-1.785)+ 0.00*(0+0.8*-1.351)+v = -1.377\n",
      "第16 的状态 0.25*(0+0.8*-1.320)+ 0.25*(0+0.8*-4.331)+ 0.25*(0+0.8*-4.675)+ 0.25*(0+0.8*-1.377)+v = -2.341\n",
      "第17 的状态 0.25*(0+0.8*-1.588)+ 0.25*(0+0.8*-0.969)+ 0.25*(0+0.8*-2.341)+v = -4.346\n",
      "第18 的状态 0.25*(0+0.8*-0.314)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.969)+ 0.25*(0+0.8*-4.346)+v = -0.976\n",
      "第20 的状态 0.00*(0+0.8*-1.058)+ 0.50*(0+0.8*-1.320)+ 0.50*(0+0.8*-1.377)+ 0.00*(0+0.8*-1.058)+v = -1.079\n",
      "第21 的状态 0.00*(0+0.8*-1.320)+ 0.33*(0+0.8*-1.588)+ 0.33*(0+0.8*-2.341)+ 0.33*(0+0.8*-1.079)+v = -1.335\n",
      "第22 的状态 0.00*(0+0.8*-1.588)+ 0.33*(0+0.8*-0.314)+ 0.33*(0+0.8*-4.346)+ 0.33*(0+0.8*-1.335)+v = -1.599\n",
      "第23 的状态 0.00*(0+0.8*-0.314)+ 0.33*(0+0.8*1.374)+ 0.33*(0+0.8*-0.976)+ 0.33*(0+0.8*-1.599)+v = -0.320\n",
      "第24 的状态 0.00*(0+0.8*1.374)+ 0.00*(0+0.8*1.374)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.320)+v = 1.372\n",
      "k= 9\n",
      "[[-1.0786 -1.3353 -1.5988 -0.3201  1.372 ]\n",
      " [-1.3768 -2.3405 -4.3457 -0.9758  0.    ]\n",
      " [-1.7848 -4.6751  0.     -3.969  -0.2903]\n",
      " [-0.6936 -2.1221 -4.6119 -2.1348 -0.8696]\n",
      " [ 0.     -0.6803 -1.7316 -1.2467 -0.8419]]\n",
      "第1 的状态 0.33*(0+0.8*-2.122)+ 0.33*(0+0.8*-1.732)+ 0.00*(0+0.8*-0.680)+ 0.33*(1+0.8*0.000)+v = -0.694\n",
      "第2 的状态 0.33*(0+0.8*-4.612)+ 0.33*(0+0.8*-1.247)+ 0.00*(0+0.8*-1.732)+ 0.33*(0+0.8*-0.694)+v = -1.747\n",
      "第3 的状态 0.33*(0+0.8*-2.135)+ 0.33*(0+0.8*-0.842)+ 0.00*(0+0.8*-1.247)+ 0.33*(0+0.8*-1.747)+v = -1.260\n",
      "第4 的状态 0.50*(0+0.8*-0.870)+ 0.00*(0+0.8*-0.842)+ 0.00*(0+0.8*-0.842)+ 0.50*(0+0.8*-1.260)+v = -0.852\n",
      "第5 的状态 0.33*(0+0.8*-1.785)+ 0.33*(0+0.8*-2.122)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.694)+v = -0.709\n",
      "第6 的状态 0.25*(0+0.8*-4.675)+ 0.25*(0+0.8*-4.612)+ 0.25*(0+0.8*-0.694)+ 0.25*(0+0.8*-0.709)+v = -2.138\n",
      "第7 的状态 0.25*(0+0.8*-2.135)+ 0.25*(0+0.8*-1.747)+ 0.25*(0+0.8*-2.138)+v = -4.626\n",
      "第8 的状态 0.25*(0+0.8*-3.969)+ 0.25*(0+0.8*-0.870)+ 0.25*(0+0.8*-1.260)+ 0.25*(0+0.8*-4.626)+v = -2.145\n",
      "第9 的状态 0.33*(0+0.8*-0.290)+ 0.00*(0+0.8*-0.870)+ 0.33*(0+0.8*-0.852)+ 0.33*(0+0.8*-2.145)+v = -0.877\n",
      "第10 的状态 0.33*(0+0.8*-1.377)+ 0.33*(0+0.8*-4.675)+ 0.33*(0+0.8*-0.709)+ 0.00*(0+0.8*-1.785)+v = -1.803\n",
      "第11 的状态 0.25*(0+0.8*-2.341)+ 0.25*(0+0.8*-2.138)+ 0.25*(0+0.8*-1.803)+v = -4.691\n",
      "第13 的状态 0.25*(0+0.8*-0.976)+ 0.25*(0+0.8*-0.290)+ 0.25*(0+0.8*-2.145)+v = -3.976\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.290)+ 0.33*(0+0.8*-0.877)+ 0.33*(0+0.8*-3.976)+v = -0.294\n",
      "第15 的状态 0.33*(0+0.8*-1.079)+ 0.33*(0+0.8*-2.341)+ 0.33*(0+0.8*-1.803)+ 0.00*(0+0.8*-1.377)+v = -1.393\n",
      "第16 的状态 0.25*(0+0.8*-1.335)+ 0.25*(0+0.8*-4.346)+ 0.25*(0+0.8*-4.691)+ 0.25*(0+0.8*-1.393)+v = -2.353\n",
      "第17 的状态 0.25*(0+0.8*-1.599)+ 0.25*(0+0.8*-0.976)+ 0.25*(0+0.8*-2.353)+v = -4.355\n",
      "第18 的状态 0.25*(0+0.8*-0.320)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.976)+ 0.25*(0+0.8*-4.355)+v = -0.980\n",
      "第20 的状态 0.00*(0+0.8*-1.079)+ 0.50*(0+0.8*-1.335)+ 0.50*(0+0.8*-1.393)+ 0.00*(0+0.8*-1.079)+v = -1.091\n",
      "第21 的状态 0.00*(0+0.8*-1.335)+ 0.33*(0+0.8*-1.599)+ 0.33*(0+0.8*-2.353)+ 0.33*(0+0.8*-1.091)+v = -1.345\n",
      "第22 的状态 0.00*(0+0.8*-1.599)+ 0.33*(0+0.8*-0.320)+ 0.33*(0+0.8*-4.355)+ 0.33*(0+0.8*-1.345)+v = -1.605\n",
      "第23 的状态 0.00*(0+0.8*-0.320)+ 0.33*(0+0.8*1.372)+ 0.33*(0+0.8*-0.980)+ 0.33*(0+0.8*-1.605)+v = -0.324\n",
      "第24 的状态 0.00*(0+0.8*1.372)+ 0.00*(0+0.8*1.372)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.324)+v = 1.371\n",
      "k= 10\n",
      "[[-1.0911 -1.3448 -1.6052 -0.3236  1.3706]\n",
      " [-1.3925 -2.353  -4.3546 -0.9801  0.    ]\n",
      " [-1.8028 -4.6913  0.     -3.976  -0.294 ]\n",
      " [-0.7085 -2.138  -4.6264 -2.145  -0.8765]\n",
      " [ 0.     -0.6943 -1.7474 -1.2598 -0.8517]]\n",
      "第1 的状态 0.33*(0+0.8*-2.138)+ 0.33*(0+0.8*-1.747)+ 0.00*(0+0.8*-0.694)+ 0.33*(1+0.8*0.000)+v = -0.703\n",
      "第2 的状态 0.33*(0+0.8*-4.626)+ 0.33*(0+0.8*-1.260)+ 0.00*(0+0.8*-1.747)+ 0.33*(0+0.8*-0.703)+v = -1.757\n",
      "第3 的状态 0.33*(0+0.8*-2.145)+ 0.33*(0+0.8*-0.852)+ 0.00*(0+0.8*-1.260)+ 0.33*(0+0.8*-1.757)+v = -1.268\n",
      "第4 的状态 0.50*(0+0.8*-0.877)+ 0.00*(0+0.8*-0.852)+ 0.00*(0+0.8*-0.852)+ 0.50*(0+0.8*-1.268)+v = -0.858\n",
      "第5 的状态 0.33*(0+0.8*-1.803)+ 0.33*(0+0.8*-2.138)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.709)+v = -0.718\n",
      "第6 的状态 0.25*(0+0.8*-4.691)+ 0.25*(0+0.8*-4.626)+ 0.25*(0+0.8*-0.703)+ 0.25*(0+0.8*-0.718)+v = -2.148\n",
      "第7 的状态 0.25*(0+0.8*-2.145)+ 0.25*(0+0.8*-1.757)+ 0.25*(0+0.8*-2.148)+v = -4.635\n",
      "第8 的状态 0.25*(0+0.8*-3.976)+ 0.25*(0+0.8*-0.877)+ 0.25*(0+0.8*-1.268)+ 0.25*(0+0.8*-4.635)+v = -2.151\n",
      "第9 的状态 0.33*(0+0.8*-0.294)+ 0.00*(0+0.8*-0.877)+ 0.33*(0+0.8*-0.858)+ 0.33*(0+0.8*-2.151)+v = -0.881\n",
      "第10 的状态 0.33*(0+0.8*-1.393)+ 0.33*(0+0.8*-4.691)+ 0.33*(0+0.8*-0.718)+ 0.00*(0+0.8*-1.803)+v = -1.814\n",
      "第11 的状态 0.25*(0+0.8*-2.353)+ 0.25*(0+0.8*-2.148)+ 0.25*(0+0.8*-1.814)+v = -4.701\n",
      "第13 的状态 0.25*(0+0.8*-0.980)+ 0.25*(0+0.8*-0.294)+ 0.25*(0+0.8*-2.151)+v = -3.980\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.294)+ 0.33*(0+0.8*-0.881)+ 0.33*(0+0.8*-3.980)+v = -0.296\n",
      "第15 的状态 0.33*(0+0.8*-1.091)+ 0.33*(0+0.8*-2.353)+ 0.33*(0+0.8*-1.814)+ 0.00*(0+0.8*-1.393)+v = -1.402\n",
      "第16 的状态 0.25*(0+0.8*-1.345)+ 0.25*(0+0.8*-4.355)+ 0.25*(0+0.8*-4.701)+ 0.25*(0+0.8*-1.402)+v = -2.361\n",
      "第17 的状态 0.25*(0+0.8*-1.605)+ 0.25*(0+0.8*-0.980)+ 0.25*(0+0.8*-2.361)+v = -4.360\n",
      "第18 的状态 0.25*(0+0.8*-0.324)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.980)+ 0.25*(0+0.8*-4.360)+v = -0.983\n",
      "第20 的状态 0.00*(0+0.8*-1.091)+ 0.50*(0+0.8*-1.345)+ 0.50*(0+0.8*-1.402)+ 0.00*(0+0.8*-1.091)+v = -1.099\n",
      "第21 的状态 0.00*(0+0.8*-1.345)+ 0.33*(0+0.8*-1.605)+ 0.33*(0+0.8*-2.361)+ 0.33*(0+0.8*-1.099)+v = -1.351\n",
      "第22 的状态 0.00*(0+0.8*-1.605)+ 0.33*(0+0.8*-0.324)+ 0.33*(0+0.8*-4.360)+ 0.33*(0+0.8*-1.351)+v = -1.609\n",
      "第23 的状态 0.00*(0+0.8*-0.324)+ 0.33*(0+0.8*1.371)+ 0.33*(0+0.8*-0.983)+ 0.33*(0+0.8*-1.609)+v = -0.326\n",
      "第24 的状态 0.00*(0+0.8*1.371)+ 0.00*(0+0.8*1.371)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.326)+v = 1.370\n",
      "k= 11\n",
      "[[-1.0987 -1.3505 -1.6091 -0.3257  1.3697]\n",
      " [-1.4021 -2.3605 -4.3601 -0.9828  0.    ]\n",
      " [-1.8137 -4.7011  0.     -3.9802 -0.2963]\n",
      " [-0.7175 -2.1476 -4.6352 -2.1511 -0.8807]\n",
      " [ 0.     -0.7028 -1.7571 -1.2677 -0.8577]]\n",
      "第1 的状态 0.33*(0+0.8*-2.148)+ 0.33*(0+0.8*-1.757)+ 0.00*(0+0.8*-0.703)+ 0.33*(1+0.8*0.000)+v = -0.708\n",
      "第2 的状态 0.33*(0+0.8*-4.635)+ 0.33*(0+0.8*-1.268)+ 0.00*(0+0.8*-1.757)+ 0.33*(0+0.8*-0.708)+v = -1.763\n",
      "第3 的状态 0.33*(0+0.8*-2.151)+ 0.33*(0+0.8*-0.858)+ 0.00*(0+0.8*-1.268)+ 0.33*(0+0.8*-1.763)+v = -1.272\n",
      "第4 的状态 0.50*(0+0.8*-0.881)+ 0.00*(0+0.8*-0.858)+ 0.00*(0+0.8*-0.858)+ 0.50*(0+0.8*-1.272)+v = -0.861\n",
      "第5 的状态 0.33*(0+0.8*-1.814)+ 0.33*(0+0.8*-2.148)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.718)+v = -0.723\n",
      "第6 的状态 0.25*(0+0.8*-4.701)+ 0.25*(0+0.8*-4.635)+ 0.25*(0+0.8*-0.708)+ 0.25*(0+0.8*-0.723)+v = -2.153\n",
      "第7 的状态 0.25*(0+0.8*-2.151)+ 0.25*(0+0.8*-1.763)+ 0.25*(0+0.8*-2.153)+v = -4.641\n",
      "第8 的状态 0.25*(0+0.8*-3.980)+ 0.25*(0+0.8*-0.881)+ 0.25*(0+0.8*-1.272)+ 0.25*(0+0.8*-4.641)+v = -2.155\n",
      "第9 的状态 0.33*(0+0.8*-0.296)+ 0.00*(0+0.8*-0.881)+ 0.33*(0+0.8*-0.861)+ 0.33*(0+0.8*-2.155)+v = -0.883\n",
      "第10 的状态 0.33*(0+0.8*-1.402)+ 0.33*(0+0.8*-4.701)+ 0.33*(0+0.8*-0.723)+ 0.00*(0+0.8*-1.814)+v = -1.820\n",
      "第11 的状态 0.25*(0+0.8*-2.361)+ 0.25*(0+0.8*-2.153)+ 0.25*(0+0.8*-1.820)+v = -4.707\n",
      "第13 的状态 0.25*(0+0.8*-0.983)+ 0.25*(0+0.8*-0.296)+ 0.25*(0+0.8*-2.155)+v = -3.983\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.296)+ 0.33*(0+0.8*-0.883)+ 0.33*(0+0.8*-3.983)+v = -0.298\n",
      "第15 的状态 0.33*(0+0.8*-1.099)+ 0.33*(0+0.8*-2.361)+ 0.33*(0+0.8*-1.820)+ 0.00*(0+0.8*-1.402)+v = -1.408\n",
      "第16 的状态 0.25*(0+0.8*-1.351)+ 0.25*(0+0.8*-4.360)+ 0.25*(0+0.8*-4.707)+ 0.25*(0+0.8*-1.408)+v = -2.365\n",
      "第17 的状态 0.25*(0+0.8*-1.609)+ 0.25*(0+0.8*-0.983)+ 0.25*(0+0.8*-2.365)+v = -4.363\n",
      "第18 的状态 0.25*(0+0.8*-0.326)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.983)+ 0.25*(0+0.8*-4.363)+v = -0.984\n",
      "第20 的状态 0.00*(0+0.8*-1.099)+ 0.50*(0+0.8*-1.351)+ 0.50*(0+0.8*-1.408)+ 0.00*(0+0.8*-1.099)+v = -1.103\n",
      "第21 的状态 0.00*(0+0.8*-1.351)+ 0.33*(0+0.8*-1.609)+ 0.33*(0+0.8*-2.365)+ 0.33*(0+0.8*-1.103)+v = -1.354\n",
      "第22 的状态 0.00*(0+0.8*-1.609)+ 0.33*(0+0.8*-0.326)+ 0.33*(0+0.8*-4.363)+ 0.33*(0+0.8*-1.354)+v = -1.612\n",
      "第23 的状态 0.00*(0+0.8*-0.326)+ 0.33*(0+0.8*1.370)+ 0.33*(0+0.8*-0.984)+ 0.33*(0+0.8*-1.612)+v = -0.327\n",
      "第24 的状态 0.00*(0+0.8*1.370)+ 0.00*(0+0.8*1.370)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.327)+v = 1.369\n",
      "k= 12\n",
      "[[-1.1034 -1.354  -1.6115 -0.327   1.3692]\n",
      " [-1.4079 -2.3651 -4.3634 -0.9844  0.    ]\n",
      " [-1.8203 -4.7071  0.     -3.9828 -0.2976]\n",
      " [-0.723  -2.1534 -4.6405 -2.1548 -0.8833]\n",
      " [ 0.     -0.7079 -1.7629 -1.2724 -0.8613]]\n",
      "第1 的状态 0.33*(0+0.8*-2.153)+ 0.33*(0+0.8*-1.763)+ 0.00*(0+0.8*-0.708)+ 0.33*(1+0.8*0.000)+v = -0.711\n",
      "第2 的状态 0.33*(0+0.8*-4.641)+ 0.33*(0+0.8*-1.272)+ 0.00*(0+0.8*-1.763)+ 0.33*(0+0.8*-0.711)+v = -1.766\n",
      "第3 的状态 0.33*(0+0.8*-2.155)+ 0.33*(0+0.8*-0.861)+ 0.00*(0+0.8*-1.272)+ 0.33*(0+0.8*-1.766)+v = -1.275\n",
      "第4 的状态 0.50*(0+0.8*-0.883)+ 0.00*(0+0.8*-0.861)+ 0.00*(0+0.8*-0.861)+ 0.50*(0+0.8*-1.275)+v = -0.863\n",
      "第5 的状态 0.33*(0+0.8*-1.820)+ 0.33*(0+0.8*-2.153)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.723)+v = -0.726\n",
      "第6 的状态 0.25*(0+0.8*-4.707)+ 0.25*(0+0.8*-4.641)+ 0.25*(0+0.8*-0.711)+ 0.25*(0+0.8*-0.726)+v = -2.157\n",
      "第7 的状态 0.25*(0+0.8*-2.155)+ 0.25*(0+0.8*-1.766)+ 0.25*(0+0.8*-2.157)+v = -4.644\n",
      "第8 的状态 0.25*(0+0.8*-3.983)+ 0.25*(0+0.8*-0.883)+ 0.25*(0+0.8*-1.275)+ 0.25*(0+0.8*-4.644)+v = -2.157\n",
      "第9 的状态 0.33*(0+0.8*-0.298)+ 0.00*(0+0.8*-0.883)+ 0.33*(0+0.8*-0.863)+ 0.33*(0+0.8*-2.157)+v = -0.885\n",
      "第10 的状态 0.33*(0+0.8*-1.408)+ 0.33*(0+0.8*-4.707)+ 0.33*(0+0.8*-0.726)+ 0.00*(0+0.8*-1.820)+v = -1.824\n",
      "第11 的状态 0.25*(0+0.8*-2.365)+ 0.25*(0+0.8*-2.157)+ 0.25*(0+0.8*-1.824)+v = -4.711\n",
      "第13 的状态 0.25*(0+0.8*-0.984)+ 0.25*(0+0.8*-0.298)+ 0.25*(0+0.8*-2.157)+v = -3.984\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.298)+ 0.33*(0+0.8*-0.885)+ 0.33*(0+0.8*-3.984)+v = -0.298\n",
      "第15 的状态 0.33*(0+0.8*-1.103)+ 0.33*(0+0.8*-2.365)+ 0.33*(0+0.8*-1.824)+ 0.00*(0+0.8*-1.408)+v = -1.411\n",
      "第16 的状态 0.25*(0+0.8*-1.354)+ 0.25*(0+0.8*-4.363)+ 0.25*(0+0.8*-4.711)+ 0.25*(0+0.8*-1.411)+v = -2.368\n",
      "第17 的状态 0.25*(0+0.8*-1.612)+ 0.25*(0+0.8*-0.984)+ 0.25*(0+0.8*-2.368)+v = -4.365\n",
      "第18 的状态 0.25*(0+0.8*-0.327)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.984)+ 0.25*(0+0.8*-4.365)+v = -0.985\n",
      "第20 的状态 0.00*(0+0.8*-1.103)+ 0.50*(0+0.8*-1.354)+ 0.50*(0+0.8*-1.411)+ 0.00*(0+0.8*-1.103)+v = -1.106\n",
      "第21 的状态 0.00*(0+0.8*-1.354)+ 0.33*(0+0.8*-1.612)+ 0.33*(0+0.8*-2.368)+ 0.33*(0+0.8*-1.106)+v = -1.356\n",
      "第22 的状态 0.00*(0+0.8*-1.612)+ 0.33*(0+0.8*-0.327)+ 0.33*(0+0.8*-4.365)+ 0.33*(0+0.8*-1.356)+v = -1.613\n",
      "第23 的状态 0.00*(0+0.8*-0.327)+ 0.33*(0+0.8*1.369)+ 0.33*(0+0.8*-0.985)+ 0.33*(0+0.8*-1.613)+v = -0.328\n",
      "第24 的状态 0.00*(0+0.8*1.369)+ 0.00*(0+0.8*1.369)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.328)+v = 1.369\n",
      "k= 13\n",
      "[[-1.1062 -1.3562 -1.613  -0.3278  1.3689]\n",
      " [-1.4114 -2.3679 -4.3654 -0.9854  0.    ]\n",
      " [-1.8243 -4.7107  0.     -3.9844 -0.2985]\n",
      " [-0.7263 -2.157  -4.6437 -2.157  -0.8848]\n",
      " [ 0.     -0.711  -1.7664 -1.2753 -0.8634]]\n",
      "第1 的状态 0.33*(0+0.8*-2.157)+ 0.33*(0+0.8*-1.766)+ 0.00*(0+0.8*-0.711)+ 0.33*(1+0.8*0.000)+v = -0.713\n",
      "第2 的状态 0.33*(0+0.8*-4.644)+ 0.33*(0+0.8*-1.275)+ 0.00*(0+0.8*-1.766)+ 0.33*(0+0.8*-0.713)+v = -1.769\n",
      "第3 的状态 0.33*(0+0.8*-2.157)+ 0.33*(0+0.8*-0.863)+ 0.00*(0+0.8*-1.275)+ 0.33*(0+0.8*-1.769)+v = -1.277\n",
      "第4 的状态 0.50*(0+0.8*-0.885)+ 0.00*(0+0.8*-0.863)+ 0.00*(0+0.8*-0.863)+ 0.50*(0+0.8*-1.277)+v = -0.865\n",
      "第5 的状态 0.33*(0+0.8*-1.824)+ 0.33*(0+0.8*-2.157)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.726)+v = -0.728\n",
      "第6 的状态 0.25*(0+0.8*-4.711)+ 0.25*(0+0.8*-4.644)+ 0.25*(0+0.8*-0.713)+ 0.25*(0+0.8*-0.728)+v = -2.159\n",
      "第7 的状态 0.25*(0+0.8*-2.157)+ 0.25*(0+0.8*-1.769)+ 0.25*(0+0.8*-2.159)+v = -4.646\n",
      "第8 的状态 0.25*(0+0.8*-3.984)+ 0.25*(0+0.8*-0.885)+ 0.25*(0+0.8*-1.277)+ 0.25*(0+0.8*-4.646)+v = -2.158\n",
      "第9 的状态 0.33*(0+0.8*-0.298)+ 0.00*(0+0.8*-0.885)+ 0.33*(0+0.8*-0.865)+ 0.33*(0+0.8*-2.158)+v = -0.886\n",
      "第10 的状态 0.33*(0+0.8*-1.411)+ 0.33*(0+0.8*-4.711)+ 0.33*(0+0.8*-0.728)+ 0.00*(0+0.8*-1.824)+v = -1.827\n",
      "第11 的状态 0.25*(0+0.8*-2.368)+ 0.25*(0+0.8*-2.159)+ 0.25*(0+0.8*-1.827)+v = -4.713\n",
      "第13 的状态 0.25*(0+0.8*-0.985)+ 0.25*(0+0.8*-0.298)+ 0.25*(0+0.8*-2.158)+v = -3.985\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.298)+ 0.33*(0+0.8*-0.886)+ 0.33*(0+0.8*-3.985)+v = -0.299\n",
      "第15 的状态 0.33*(0+0.8*-1.106)+ 0.33*(0+0.8*-2.368)+ 0.33*(0+0.8*-1.827)+ 0.00*(0+0.8*-1.411)+v = -1.414\n",
      "第16 的状态 0.25*(0+0.8*-1.356)+ 0.25*(0+0.8*-4.365)+ 0.25*(0+0.8*-4.713)+ 0.25*(0+0.8*-1.414)+v = -2.370\n",
      "第17 的状态 0.25*(0+0.8*-1.613)+ 0.25*(0+0.8*-0.985)+ 0.25*(0+0.8*-2.370)+v = -4.367\n",
      "第18 的状态 0.25*(0+0.8*-0.328)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.985)+ 0.25*(0+0.8*-4.367)+v = -0.986\n",
      "第20 的状态 0.00*(0+0.8*-1.106)+ 0.50*(0+0.8*-1.356)+ 0.50*(0+0.8*-1.414)+ 0.00*(0+0.8*-1.106)+v = -1.108\n",
      "第21 的状态 0.00*(0+0.8*-1.356)+ 0.33*(0+0.8*-1.613)+ 0.33*(0+0.8*-2.370)+ 0.33*(0+0.8*-1.108)+v = -1.357\n",
      "第22 的状态 0.00*(0+0.8*-1.613)+ 0.33*(0+0.8*-0.328)+ 0.33*(0+0.8*-4.367)+ 0.33*(0+0.8*-1.357)+v = -1.614\n",
      "第23 的状态 0.00*(0+0.8*-0.328)+ 0.33*(0+0.8*1.369)+ 0.33*(0+0.8*-0.986)+ 0.33*(0+0.8*-1.614)+v = -0.328\n",
      "第24 的状态 0.00*(0+0.8*1.369)+ 0.00*(0+0.8*1.369)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.328)+v = 1.369\n",
      "k= 14\n",
      "[[-1.1079 -1.3575 -1.6138 -0.3282  1.3687]\n",
      " [-1.4136 -2.3696 -4.3667 -0.986   0.    ]\n",
      " [-1.8268 -4.7129  0.     -3.9853 -0.299 ]\n",
      " [-0.7284 -2.1591 -4.6457 -2.1584 -0.8858]\n",
      " [ 0.     -0.7129 -1.7685 -1.2771 -0.8648]]\n",
      "第1 的状态 0.33*(0+0.8*-2.159)+ 0.33*(0+0.8*-1.769)+ 0.00*(0+0.8*-0.713)+ 0.33*(1+0.8*0.000)+v = -0.714\n",
      "第2 的状态 0.33*(0+0.8*-4.646)+ 0.33*(0+0.8*-1.277)+ 0.00*(0+0.8*-1.769)+ 0.33*(0+0.8*-0.714)+v = -1.770\n",
      "第3 的状态 0.33*(0+0.8*-2.158)+ 0.33*(0+0.8*-0.865)+ 0.00*(0+0.8*-1.277)+ 0.33*(0+0.8*-1.770)+v = -1.278\n",
      "第4 的状态 0.50*(0+0.8*-0.886)+ 0.00*(0+0.8*-0.865)+ 0.00*(0+0.8*-0.865)+ 0.50*(0+0.8*-1.278)+v = -0.866\n",
      "第5 的状态 0.33*(0+0.8*-1.827)+ 0.33*(0+0.8*-2.159)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.728)+v = -0.730\n",
      "第6 的状态 0.25*(0+0.8*-4.713)+ 0.25*(0+0.8*-4.646)+ 0.25*(0+0.8*-0.714)+ 0.25*(0+0.8*-0.730)+v = -2.160\n",
      "第7 的状态 0.25*(0+0.8*-2.158)+ 0.25*(0+0.8*-1.770)+ 0.25*(0+0.8*-2.160)+v = -4.647\n",
      "第8 的状态 0.25*(0+0.8*-3.985)+ 0.25*(0+0.8*-0.886)+ 0.25*(0+0.8*-1.278)+ 0.25*(0+0.8*-4.647)+v = -2.159\n",
      "第9 的状态 0.33*(0+0.8*-0.299)+ 0.00*(0+0.8*-0.886)+ 0.33*(0+0.8*-0.866)+ 0.33*(0+0.8*-2.159)+v = -0.886\n",
      "第10 的状态 0.33*(0+0.8*-1.414)+ 0.33*(0+0.8*-4.713)+ 0.33*(0+0.8*-0.730)+ 0.00*(0+0.8*-1.827)+v = -1.828\n",
      "第11 的状态 0.25*(0+0.8*-2.370)+ 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.828)+v = -4.714\n",
      "第13 的状态 0.25*(0+0.8*-0.986)+ 0.25*(0+0.8*-0.299)+ 0.25*(0+0.8*-2.159)+v = -3.986\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.299)+ 0.33*(0+0.8*-0.886)+ 0.33*(0+0.8*-3.986)+v = -0.299\n",
      "第15 的状态 0.33*(0+0.8*-1.108)+ 0.33*(0+0.8*-2.370)+ 0.33*(0+0.8*-1.828)+ 0.00*(0+0.8*-1.414)+v = -1.415\n",
      "第16 的状态 0.25*(0+0.8*-1.357)+ 0.25*(0+0.8*-4.367)+ 0.25*(0+0.8*-4.714)+ 0.25*(0+0.8*-1.415)+v = -2.371\n",
      "第17 的状态 0.25*(0+0.8*-1.614)+ 0.25*(0+0.8*-0.986)+ 0.25*(0+0.8*-2.371)+v = -4.367\n",
      "第18 的状态 0.25*(0+0.8*-0.328)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.986)+ 0.25*(0+0.8*-4.367)+v = -0.986\n",
      "第20 的状态 0.00*(0+0.8*-1.108)+ 0.50*(0+0.8*-1.357)+ 0.50*(0+0.8*-1.415)+ 0.00*(0+0.8*-1.108)+v = -1.109\n",
      "第21 的状态 0.00*(0+0.8*-1.357)+ 0.33*(0+0.8*-1.614)+ 0.33*(0+0.8*-2.371)+ 0.33*(0+0.8*-1.109)+v = -1.358\n",
      "第22 的状态 0.00*(0+0.8*-1.614)+ 0.33*(0+0.8*-0.328)+ 0.33*(0+0.8*-4.367)+ 0.33*(0+0.8*-1.358)+v = -1.614\n",
      "第23 的状态 0.00*(0+0.8*-0.328)+ 0.33*(0+0.8*1.369)+ 0.33*(0+0.8*-0.986)+ 0.33*(0+0.8*-1.614)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.369)+ 0.00*(0+0.8*1.369)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.369\n",
      "k= 15\n",
      "[[-1.1089 -1.3582 -1.6144 -0.3285  1.3686]\n",
      " [-1.4149 -2.3707 -4.3674 -0.9863  0.    ]\n",
      " [-1.8283 -4.7143  0.     -3.9859 -0.2993]\n",
      " [-0.7296 -2.1604 -4.6469 -2.1592 -0.8863]\n",
      " [ 0.     -0.714  -1.7698 -1.2781 -0.8656]]\n",
      "第1 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-1.770)+ 0.00*(0+0.8*-0.714)+ 0.33*(1+0.8*0.000)+v = -0.715\n",
      "第2 的状态 0.33*(0+0.8*-4.647)+ 0.33*(0+0.8*-1.278)+ 0.00*(0+0.8*-1.770)+ 0.33*(0+0.8*-0.715)+v = -1.771\n",
      "第3 的状态 0.33*(0+0.8*-2.159)+ 0.33*(0+0.8*-0.866)+ 0.00*(0+0.8*-1.278)+ 0.33*(0+0.8*-1.771)+v = -1.279\n",
      "第4 的状态 0.50*(0+0.8*-0.886)+ 0.00*(0+0.8*-0.866)+ 0.00*(0+0.8*-0.866)+ 0.50*(0+0.8*-1.279)+v = -0.866\n",
      "第5 的状态 0.33*(0+0.8*-1.828)+ 0.33*(0+0.8*-2.160)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.730)+v = -0.730\n",
      "第6 的状态 0.25*(0+0.8*-4.714)+ 0.25*(0+0.8*-4.647)+ 0.25*(0+0.8*-0.715)+ 0.25*(0+0.8*-0.730)+v = -2.161\n",
      "第7 的状态 0.25*(0+0.8*-2.159)+ 0.25*(0+0.8*-1.771)+ 0.25*(0+0.8*-2.161)+v = -4.648\n",
      "第8 的状态 0.25*(0+0.8*-3.986)+ 0.25*(0+0.8*-0.886)+ 0.25*(0+0.8*-1.279)+ 0.25*(0+0.8*-4.648)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.299)+ 0.00*(0+0.8*-0.886)+ 0.33*(0+0.8*-0.866)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.415)+ 0.33*(0+0.8*-4.714)+ 0.33*(0+0.8*-0.730)+ 0.00*(0+0.8*-1.828)+v = -1.829\n",
      "第11 的状态 0.25*(0+0.8*-2.371)+ 0.25*(0+0.8*-2.161)+ 0.25*(0+0.8*-1.829)+v = -4.715\n",
      "第13 的状态 0.25*(0+0.8*-0.986)+ 0.25*(0+0.8*-0.299)+ 0.25*(0+0.8*-2.160)+v = -3.986\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.299)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.986)+v = -0.299\n",
      "第15 的状态 0.33*(0+0.8*-1.109)+ 0.33*(0+0.8*-2.371)+ 0.33*(0+0.8*-1.829)+ 0.00*(0+0.8*-1.415)+v = -1.416\n",
      "第16 的状态 0.25*(0+0.8*-1.358)+ 0.25*(0+0.8*-4.367)+ 0.25*(0+0.8*-4.715)+ 0.25*(0+0.8*-1.416)+v = -2.371\n",
      "第17 的状态 0.25*(0+0.8*-1.614)+ 0.25*(0+0.8*-0.986)+ 0.25*(0+0.8*-2.371)+v = -4.368\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.986)+ 0.25*(0+0.8*-4.368)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.109)+ 0.50*(0+0.8*-1.358)+ 0.50*(0+0.8*-1.416)+ 0.00*(0+0.8*-1.109)+v = -1.110\n",
      "第21 的状态 0.00*(0+0.8*-1.358)+ 0.33*(0+0.8*-1.614)+ 0.33*(0+0.8*-2.371)+ 0.33*(0+0.8*-1.110)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.614)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.368)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.369)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.369)+ 0.00*(0+0.8*1.369)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.369\n",
      "k= 16\n",
      "[[-1.1096 -1.3587 -1.6147 -0.3287  1.3685]\n",
      " [-1.4157 -2.3713 -4.3679 -0.9865  0.    ]\n",
      " [-1.8292 -4.7151  0.     -3.9862 -0.2994]\n",
      " [-0.7303 -2.1612 -4.6476 -2.1597 -0.8867]\n",
      " [ 0.     -0.7147 -1.7706 -1.2788 -0.866 ]]\n",
      "第1 的状态 0.33*(0+0.8*-2.161)+ 0.33*(0+0.8*-1.771)+ 0.00*(0+0.8*-0.715)+ 0.33*(1+0.8*0.000)+v = -0.715\n",
      "第2 的状态 0.33*(0+0.8*-4.648)+ 0.33*(0+0.8*-1.279)+ 0.00*(0+0.8*-1.771)+ 0.33*(0+0.8*-0.715)+v = -1.771\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.866)+ 0.00*(0+0.8*-1.279)+ 0.33*(0+0.8*-1.771)+v = -1.279\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.866)+ 0.00*(0+0.8*-0.866)+ 0.50*(0+0.8*-1.279)+v = -0.866\n",
      "第5 的状态 0.33*(0+0.8*-1.829)+ 0.33*(0+0.8*-2.161)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.730)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.715)+ 0.25*(0+0.8*-4.648)+ 0.25*(0+0.8*-0.715)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.771)+ 0.25*(0+0.8*-2.162)+v = -4.648\n",
      "第8 的状态 0.25*(0+0.8*-3.986)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.279)+ 0.25*(0+0.8*-4.648)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.299)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.866)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.416)+ 0.33*(0+0.8*-4.715)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.829)+v = -1.830\n",
      "第11 的状态 0.25*(0+0.8*-2.371)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.830)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.299)+ 0.25*(0+0.8*-2.160)+v = -3.986\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.299)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.986)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.110)+ 0.33*(0+0.8*-2.371)+ 0.33*(0+0.8*-1.830)+ 0.00*(0+0.8*-1.416)+v = -1.416\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.368)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.416)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.368\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.986)+ 0.25*(0+0.8*-4.368)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.110)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.416)+ 0.00*(0+0.8*-1.110)+v = -1.110\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.110)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.368)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.369)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.369)+ 0.00*(0+0.8*1.369)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 17\n",
      "[[-1.11   -1.359  -1.6149 -0.3288  1.3685]\n",
      " [-1.4162 -2.3717 -4.3682 -0.9867  0.    ]\n",
      " [-1.8297 -4.7156  0.     -3.9864 -0.2996]\n",
      " [-0.7308 -2.1617 -4.648  -2.16   -0.8869]\n",
      " [ 0.     -0.7152 -1.7711 -1.2792 -0.8663]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.771)+ 0.00*(0+0.8*-0.715)+ 0.33*(1+0.8*0.000)+v = -0.715\n",
      "第2 的状态 0.33*(0+0.8*-4.648)+ 0.33*(0+0.8*-1.279)+ 0.00*(0+0.8*-1.771)+ 0.33*(0+0.8*-0.715)+v = -1.771\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.866)+ 0.00*(0+0.8*-1.279)+ 0.33*(0+0.8*-1.771)+v = -1.279\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.866)+ 0.00*(0+0.8*-0.866)+ 0.50*(0+0.8*-1.279)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.830)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.648)+ 0.25*(0+0.8*-0.715)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.771)+ 0.25*(0+0.8*-2.162)+v = -4.648\n",
      "第8 的状态 0.25*(0+0.8*-3.986)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.279)+ 0.25*(0+0.8*-4.648)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.416)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.830)+v = -1.830\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.830)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.110)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.830)+ 0.00*(0+0.8*-1.416)+v = -1.416\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.368)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.416)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.368\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.368)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.110)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.416)+ 0.00*(0+0.8*-1.110)+v = -1.110\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.110)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.368)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 18\n",
      "[[-1.1102 -1.3592 -1.615  -0.3289  1.3684]\n",
      " [-1.4165 -2.3719 -4.3683 -0.9867  0.    ]\n",
      " [-1.8301 -4.7159  0.     -3.9866 -0.2996]\n",
      " [-0.7311 -2.162  -4.6483 -2.1602 -0.887 ]\n",
      " [ 0.     -0.7154 -1.7714 -1.2794 -0.8665]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.771)+ 0.00*(0+0.8*-0.715)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.648)+ 0.33*(0+0.8*-1.279)+ 0.00*(0+0.8*-1.771)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.279)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.830)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.648)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.648\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.648)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.416)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.830)+v = -1.830\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.830)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.110)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.830)+ 0.00*(0+0.8*-1.416)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.368)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.368\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.368)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.110)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.110)+v = -1.110\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.110)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.368)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 19\n",
      "[[-1.1103 -1.3593 -1.6151 -0.3289  1.3684]\n",
      " [-1.4166 -2.372  -4.3684 -0.9868  0.    ]\n",
      " [-1.8303 -4.716   0.     -3.9866 -0.2997]\n",
      " [-0.7312 -2.1622 -4.6484 -2.1603 -0.8871]\n",
      " [ 0.     -0.7156 -1.7715 -1.2795 -0.8666]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.648)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.830)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.648)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.830)+v = -1.830\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.830)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.110)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.830)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.368)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.368\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.368)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.110)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.110)+v = -1.110\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.110)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.368)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 20\n",
      "[[-1.1104 -1.3594 -1.6151 -0.3289  1.3684]\n",
      " [-1.4167 -2.3721 -4.3685 -0.9868  0.    ]\n",
      " [-1.8304 -4.7162  0.     -3.9867 -0.2997]\n",
      " [-0.7313 -2.1623 -4.6485 -2.1604 -0.8871]\n",
      " [ 0.     -0.7157 -1.7716 -1.2796 -0.8667]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.649)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.830)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.649)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.830)+v = -1.830\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.830)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.110)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.830)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.368)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.369\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.369)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.110)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.110)+v = -1.110\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.110)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.369)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 21\n",
      "[[-1.1105 -1.3594 -1.6152 -0.329   1.3684]\n",
      " [-1.4168 -2.3722 -4.3685 -0.9868  0.    ]\n",
      " [-1.8305 -4.7162  0.     -3.9867 -0.2997]\n",
      " [-0.7314 -2.1624 -4.6486 -2.1604 -0.8872]\n",
      " [ 0.     -0.7157 -1.7717 -1.2797 -0.8667]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.649)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.830)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.649)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.830)+v = -1.831\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.831)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.110)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.831)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.369)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.369\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.369)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.110)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.110)+v = -1.111\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.111)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.369)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 22\n",
      "[[-1.1105 -1.3594 -1.6152 -0.329   1.3684]\n",
      " [-1.4168 -2.3722 -4.3685 -0.9868  0.    ]\n",
      " [-1.8305 -4.7163  0.     -3.9867 -0.2997]\n",
      " [-0.7314 -2.1624 -4.6486 -2.1604 -0.8872]\n",
      " [ 0.     -0.7157 -1.7717 -1.2797 -0.8667]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.649)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.831)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.649)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.831)+v = -1.831\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.831)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.111)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.831)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.369)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.369\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.369)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.111)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.111)+v = -1.111\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.111)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.369)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 23\n",
      "[[-1.1105 -1.3594 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3722 -4.3686 -0.9869  0.    ]\n",
      " [-1.8305 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7314 -2.1624 -4.6486 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.649)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.831)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.649)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.831)+v = -1.831\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.831)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.111)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.831)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.369)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.369\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.369)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.111)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.111)+v = -1.111\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.111)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.369)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 24\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3722 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1624 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.649)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.831)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.649)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.831)+v = -1.831\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.831)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.111)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.831)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.369)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.369\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.369)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.111)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.111)+v = -1.111\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.111)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.369)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 25\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3722 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1624 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.649)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.831)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.649)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.831)+v = -1.831\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.831)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.111)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.831)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.369)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.369\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.369)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.111)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.111)+v = -1.111\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.111)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.369)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 26\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3723 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1624 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第2 的状态 0.33*(0+0.8*-4.649)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.831)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.649)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.831)+v = -1.831\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.831)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.111)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.831)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.369)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.369\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.369)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.111)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.111)+v = -1.111\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.111)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.369)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 27\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3723 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1625 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.649)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.831)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.649)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.831)+v = -1.831\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.831)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.111)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.831)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.369)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.369\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.369)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.111)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.111)+v = -1.111\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.111)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.369)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 28\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3723 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1625 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.649)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.831)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.649)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.831)+v = -1.831\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.831)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.111)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.831)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.369)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.369\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.369)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.111)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.111)+v = -1.111\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.111)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.369)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 29\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3723 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1625 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "第1 的状态 0.33*(0+0.8*-2.162)+ 0.33*(0+0.8*-1.772)+ 0.00*(0+0.8*-0.716)+ 0.33*(1+0.8*0.000)+v = -0.716\n",
      "第2 的状态 0.33*(0+0.8*-4.649)+ 0.33*(0+0.8*-1.280)+ 0.00*(0+0.8*-1.772)+ 0.33*(0+0.8*-0.716)+v = -1.772\n",
      "第3 的状态 0.33*(0+0.8*-2.160)+ 0.33*(0+0.8*-0.867)+ 0.00*(0+0.8*-1.280)+ 0.33*(0+0.8*-1.772)+v = -1.280\n",
      "第4 的状态 0.50*(0+0.8*-0.887)+ 0.00*(0+0.8*-0.867)+ 0.00*(0+0.8*-0.867)+ 0.50*(0+0.8*-1.280)+v = -0.867\n",
      "第5 的状态 0.33*(0+0.8*-1.831)+ 0.33*(0+0.8*-2.162)+ 0.33*(1+0.8*0.000)+ 0.00*(0+0.8*-0.731)+v = -0.731\n",
      "第6 的状态 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-4.649)+ 0.25*(0+0.8*-0.716)+ 0.25*(0+0.8*-0.731)+v = -2.162\n",
      "第7 的状态 0.25*(0+0.8*-2.160)+ 0.25*(0+0.8*-1.772)+ 0.25*(0+0.8*-2.162)+v = -4.649\n",
      "第8 的状态 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-0.887)+ 0.25*(0+0.8*-1.280)+ 0.25*(0+0.8*-4.649)+v = -2.160\n",
      "第9 的状态 0.33*(0+0.8*-0.300)+ 0.00*(0+0.8*-0.887)+ 0.33*(0+0.8*-0.867)+ 0.33*(0+0.8*-2.160)+v = -0.887\n",
      "第10 的状态 0.33*(0+0.8*-1.417)+ 0.33*(0+0.8*-4.716)+ 0.33*(0+0.8*-0.731)+ 0.00*(0+0.8*-1.831)+v = -1.831\n",
      "第11 的状态 0.25*(0+0.8*-2.372)+ 0.25*(0+0.8*-2.162)+ 0.25*(0+0.8*-1.831)+v = -4.716\n",
      "第13 的状态 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-0.300)+ 0.25*(0+0.8*-2.160)+v = -3.987\n",
      "第14 的状态 0.33*(3+0.8*0.000)+ 0.00*(0+0.8*-0.300)+ 0.33*(0+0.8*-0.887)+ 0.33*(0+0.8*-3.987)+v = -0.300\n",
      "第15 的状态 0.33*(0+0.8*-1.111)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.831)+ 0.00*(0+0.8*-1.417)+v = -1.417\n",
      "第16 的状态 0.25*(0+0.8*-1.359)+ 0.25*(0+0.8*-4.369)+ 0.25*(0+0.8*-4.716)+ 0.25*(0+0.8*-1.417)+v = -2.372\n",
      "第17 的状态 0.25*(0+0.8*-1.615)+ 0.25*(0+0.8*-0.987)+ 0.25*(0+0.8*-2.372)+v = -4.369\n",
      "第18 的状态 0.25*(0+0.8*-0.329)+ 0.25*(3+0.8*0.000)+ 0.25*(0+0.8*-3.987)+ 0.25*(0+0.8*-4.369)+v = -0.987\n",
      "第20 的状态 0.00*(0+0.8*-1.111)+ 0.50*(0+0.8*-1.359)+ 0.50*(0+0.8*-1.417)+ 0.00*(0+0.8*-1.111)+v = -1.111\n",
      "第21 的状态 0.00*(0+0.8*-1.359)+ 0.33*(0+0.8*-1.615)+ 0.33*(0+0.8*-2.372)+ 0.33*(0+0.8*-1.111)+v = -1.359\n",
      "第22 的状态 0.00*(0+0.8*-1.615)+ 0.33*(0+0.8*-0.329)+ 0.33*(0+0.8*-4.369)+ 0.33*(0+0.8*-1.359)+v = -1.615\n",
      "第23 的状态 0.00*(0+0.8*-0.329)+ 0.33*(0+0.8*1.368)+ 0.33*(0+0.8*-0.987)+ 0.33*(0+0.8*-1.615)+v = -0.329\n",
      "第24 的状态 0.00*(0+0.8*1.368)+ 0.00*(0+0.8*1.368)+ 0.50*(3+0.8*0.000)+ 0.50*(0+0.8*-0.329)+v = 1.368\n",
      "k= 30\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3723 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1625 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def reward(s):\n",
    "\n",
    "    if s == 20:  # 到充电站\n",
    "        return 1\n",
    "    elif s == 12:  # 到陷阱中\n",
    "        return -10\n",
    "    elif s == 9:  # 到垃圾处\n",
    "        return 3\n",
    "    else:\n",
    "        return 0  # 其他\n",
    "    # in表示0是[*，*，*]中的一个\n",
    "\n",
    "\n",
    "def getAction(a):\n",
    "    if a == 'n':\n",
    "        return 0\n",
    "    elif a == 'e':\n",
    "        return 1\n",
    "    elif a =='s':\n",
    "        return 2\n",
    "    elif a == 'w':\n",
    "        return 3\n",
    "\n",
    "# 在s状态下执行动作a，返回下一状态（编号）\n",
    "def next_states(s, a):\n",
    "    # 越过边界时pass\n",
    "    if (s < world_w and a == 'n') \\\n",
    "            or (s % world_w == 0 and a == 'w') \\\n",
    "            or (s > length - world_w - 1 and a == 's') \\\n",
    "            or ((s + 1) % world_w == 0 and a == 'e'):  # (s % (world_w - 1) == 0 and a == 'e' and s != 0)\n",
    "        next_state = s  # 表现为next_state不变\n",
    "    else:\n",
    "        next_state = s + ds_action[a]  # 进入下一个状态\n",
    "    return next_state\n",
    "\n",
    "\n",
    "# 在s状态下执行动作，返回所有可能的下一状态（编号）list\n",
    "def getsuccessor(s):\n",
    "    successor = []\n",
    "    for a in action:  # 遍历四个动作\n",
    "        if s == next_states(s,a):\n",
    "            continue\n",
    "        else:\n",
    "            # print(\"状态s=%s,动作a=%s\"%(s,a))\n",
    "            next = next_states(s, a)  # 得到下一个状态（编号）\n",
    "        successor.append(next)  # 以list保存当前状态s下执行四个动作的下一状态\n",
    "    # print(len(successor))\n",
    "    return successor\n",
    "\n",
    "def initPolicy():\n",
    "    for s in range(length):\n",
    "        for a in action:\n",
    "            if next_states(s,a) == s:\n",
    "                continue\n",
    "            newAction = getAction(a)\n",
    "            policy[s][newAction] = 1 / len(getsuccessor(s))\n",
    "    # print(policy)\n",
    "\n",
    "\n",
    "def policy_eval(theta=0.000001):\n",
    "    V = np.zeros(length)  # 初始化状态值函数列表\n",
    "    iter = 0\n",
    "\n",
    "    while True:\n",
    "        k = -1\n",
    "        delta = 0  # 定义最大差值，判断是否有进行更新\n",
    "        for s in [20,21,22,23,24,15,16,17,18,19,10,11,12,13,14,5,6,7,8,9,0,1,2,3,4]:  # 遍历所有状态 [0~25]\n",
    "            k += 1\n",
    "            if s in [9, 20,12]:  # 若当前状态为吸入状态，则直接pass不做操作\n",
    "                continue\n",
    "            v = 0  # 针对每个状态值函数进行计算\n",
    "            print(\"第%d 的状态\"%(k),end=\"\")\n",
    "            for a in action:\n",
    "                newAction = getAction(a)\n",
    "                next_state = next_states(s,a)\n",
    "                rewards = reward(next_state)\n",
    "                if next_state == 12:\n",
    "                    v += policy[s][newAction] * (rewards + gamma * V[s])\n",
    "                    # print(\" %.2f*(%d+%.1f*%.3f)+\" % (policy[s][newAction], rewards, gamma, V[next_state]), end=\"\")\n",
    "                else:\n",
    "                    v += policy[s][newAction] * (rewards + gamma * V[next_state])\n",
    "            #     print(\"%.2f*(%d+%.1f*%.2f)+\" % (policy[s][newAction], rewards, gamma, value[next_state]), end=\"\")\n",
    "            # print()\n",
    "            # successor = getsuccessor(s)\n",
    "            # for next_state in successor:\n",
    "            #     rewards = reward(next_state)\n",
    "            #     v += 1 / len(successor) * (rewards + gamma * V[next_state])\n",
    "                    print(\" %.2f*(%d+%.1f*%.3f)+\" % (policy[s][newAction], rewards, gamma, V[next_state]), end=\"\")\n",
    "            print(\"v = %.3f\"%(v))\n",
    "\n",
    "            delta = max(delta, np.abs(v - V[s]))  # 更新差值\n",
    "            V[s] = v  # 存储(更新)每个状态下的状态值函数，即伪代码中的 v <- V(s)\n",
    "        value = np.array(V).reshape(world_h, world_w)\n",
    "        iter += 1\n",
    "        print('k=', iter)  # 打印迭代次数\n",
    "        print(np.round(value, decimals=4))\n",
    "        if delta < theta:  # 策略评估的迭代次数不能太多，否则状态值函数的数值会越来越大（即使算法仍然在收敛）\n",
    "            break\n",
    "    return V  # 一轮迭代结束后，状态值函数暂时固定\n",
    "\n",
    "\n",
    "def Caculate_Q(s, V, discount_factor=0.8):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        A vector of length env.nA containing the expected value of each action.\n",
    "    \"\"\"\n",
    "    Q = np.zeros((length, 4))\n",
    "    for a in action:  # 遍历能走的动作\n",
    "        # for prob, next_state, reward, done in env.P[s][a]:\n",
    "        #     Q[s][a] += prob * (reward + discount_factor * V[next_state])  # 计算当前状态s下的动作值函数列表 [q1,q2,q3,q4]\n",
    "        next_state = next_states(s,a)\n",
    "        if next_state == s: #碰壁\n",
    "            continue\n",
    "        rewards = reward(next_state)\n",
    "        numberA = getAction(a)\n",
    "        Q[s][numberA]= rewards + discount_factor * V[next_state]\n",
    "        print(\"Q[%s][%s]  %.2f = %s + 0.8 * %.2f:\"%(s,a,Q[s][numberA],rewards,V[next_state]))\n",
    "    return Q\n",
    "\n",
    "\n",
    "world_h = 5\n",
    "world_w = 5\n",
    "length = world_h * world_w\n",
    "gamma = 0.8\n",
    "state = [i for i in range(length)]  # 状态（编号）\n",
    "action = ['n', 'e', 's', 'w']  # 动作名称\n",
    "ds_action = {'n': -world_w, 'e': 1, 's': world_w, 'w': -1}\n",
    "value = [0 for i in range(length)]  # 初始化状态值函数，均为0.  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "policy = np.zeros([length, len(action)])\n",
    "\n",
    "\n",
    "def main():\n",
    "    initPolicy()\n",
    "    value = policy_eval()\n",
    "    # v = np.array(value).reshape(world_h, world_w)\n",
    "    # print(np.round(v, decimals=2))\n",
    "    #\n",
    "    # print(Caculate_Q(3,value))\n",
    "    # initPolicy()\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "# policy, V = Policy_Iterration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**例4.2**：用同步迭代解决上述问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1\n",
      "[[ 0.      0.      0.      0.      1.5   ]\n",
      " [ 0.      0.     -2.5     0.75    0.    ]\n",
      " [ 0.     -2.5     0.     -2.5     1.    ]\n",
      " [ 0.3333  0.     -2.5     0.      0.    ]\n",
      " [ 0.      0.3333  0.      0.      0.    ]]\n",
      "k= 2\n",
      "[[ 0.      0.     -0.6667  0.6     1.5   ]\n",
      " [ 0.     -1.     -2.85   -0.25    0.    ]\n",
      " [-0.5778 -3.      0.     -2.65    0.3333]\n",
      " [ 0.3333 -0.8667 -3.     -1.      0.2667]\n",
      " [ 0.      0.3333 -0.5778  0.      0.    ]]\n",
      "k= 3\n",
      "[[ 0.     -0.4444 -0.6     0.1556  1.74  ]\n",
      " [-0.4207 -1.17   -3.4533 -0.23    0.    ]\n",
      " [-0.7111 -3.5889  0.     -3.2133  0.3644]\n",
      " [-0.0519 -1.0667 -3.5889 -1.0767 -0.1778]\n",
      " [ 0.     -0.0519 -0.7111 -0.4207  0.1067]]\n",
      "k= 4\n",
      "[[-0.3461 -0.472  -0.9979  0.2427  1.5622]\n",
      " [-0.5016 -1.5815 -3.5907 -0.5522  0.    ]\n",
      " [-1.0831 -3.8073  0.     -3.3311  0.0957]\n",
      " [-0.1407 -1.4563 -3.7887 -1.4801 -0.1615]\n",
      " [ 0.     -0.1407 -1.0831 -0.4483 -0.2394]]\n",
      "k= 5\n",
      "[[-3.8950e-01 -7.8010e-01 -1.0187e+00  3.2000e-03  1.5971e+00]\n",
      " [-8.0280e-01 -1.6743e+00 -3.8445e+00 -5.8580e-01  0.0000e+00]\n",
      " [-1.1866e+00 -4.0856e+00  0.0000e+00 -3.5536e+00  6.8600e-02]\n",
      " [-3.4380e-01 -1.5755e+00 -4.0616e+00 -1.5459e+00 -4.3300e-01]\n",
      " [ 0.0000e+00 -3.4380e-01 -1.1674e+00 -7.4740e-01 -2.4390e-01]]\n",
      "k= 6\n",
      "[[-6.3320e-01 -8.2200e-01 -1.2324e+00 -2.0000e-03  1.5013e+00]\n",
      " [-8.6680e-01 -1.9026e+00 -3.9247e+00 -7.2900e-01  0.0000e+00]\n",
      " [-1.3953e+00 -4.2044e+00  0.0000e+00 -3.6233e+00 -6.3100e-02]\n",
      " [-4.0320e-01 -1.7670e+00 -4.1701e+00 -1.7591e+00 -4.5900e-01]\n",
      " [ 0.0000e+00 -3.9810e-01 -1.3741e+00 -7.8860e-01 -4.7220e-01]]\n",
      "k= 7\n",
      "[[-0.6755 -1.0048 -1.2663 -0.1227  1.4992]\n",
      " [-1.0483 -1.9636 -4.0577 -0.76    0.    ]\n",
      " [-1.4598 -4.3539  0.     -3.7349 -0.0886]\n",
      " [-0.5099 -1.8352 -4.3141 -1.8082 -0.6118]\n",
      " [ 0.     -0.5043 -1.4285 -0.9614 -0.499 ]]\n",
      "k= 8\n",
      "[[-0.8213 -1.0414 -1.3827 -0.1406  1.4509]\n",
      " [-1.093  -2.0929 -4.1095 -0.8331  0.    ]\n",
      " [-1.5766 -4.4225  0.     -3.7783 -0.1591]\n",
      " [-0.5453 -1.9364 -4.3772 -1.9244 -0.6389]\n",
      " [ 0.     -0.537  -1.5413 -0.9962 -0.6293]]\n",
      "k= 9\n",
      "[[-0.8538 -1.1458 -1.4111 -0.204   1.4438]\n",
      " [-1.1975 -2.1333 -4.1836 -0.8557  0.    ]\n",
      " [-1.6162 -4.5057  0.     -3.839  -0.1779]\n",
      " [-0.6035 -1.9764 -4.4559 -1.9581 -0.7234]\n",
      " [ 0.     -0.5941 -1.5761 -1.092  -0.654 ]]\n",
      "k= 10\n",
      "[[-0.9374 -1.1728 -1.4756 -0.2195  1.4184]\n",
      " [-1.2275 -2.2065 -4.2167 -0.8953  0.    ]\n",
      " [-1.6818 -4.5463  0.     -3.8661 -0.2166]\n",
      " [-0.6247 -2.0318 -4.4933 -2.0221 -0.744 ]\n",
      " [ 0.     -0.614  -1.6378 -1.1169 -0.7262]]\n",
      "k= 11\n",
      "[[-0.9602 -1.2319 -1.4957 -0.254   1.4122]\n",
      " [-1.2868 -2.2327 -4.2588 -0.9105  0.    ]\n",
      " [-1.7063 -4.5933  0.     -3.9    -0.2294]\n",
      " [-0.657  -2.0557 -4.537  -2.0441 -0.7906]\n",
      " [ 0.     -0.6452 -1.6598 -1.1696 -0.7444]]\n",
      "k= 12\n",
      "[[-1.0075 -1.2503 -1.5319 -0.2651  1.3984]\n",
      " [-1.3064 -2.2742 -4.2795 -0.9326  0.    ]\n",
      " [-1.7432 -4.6176  0.     -3.9168 -0.2508]\n",
      " [-0.6699 -2.0865 -4.5593 -2.0795 -0.8047]\n",
      " [ 0.     -0.6574 -1.6938 -1.1862 -0.7841]]\n",
      "k= 13\n",
      "[[-1.0227 -1.2836 -1.5453 -0.2843  1.394 ]\n",
      " [-1.34   -2.2908 -4.3036 -0.9423  0.    ]\n",
      " [-1.7584 -4.6443  0.     -3.9359 -0.2591]\n",
      " [-0.6879 -2.1008 -4.5838 -2.0934 -0.8305]\n",
      " [ 0.     -0.6748 -1.7074 -1.2153 -0.7964]]\n",
      "k= 14\n",
      "[[-1.0494 -1.2957 -1.5657 -0.2916  1.3863]\n",
      " [-1.3525 -2.3143 -4.3164 -0.9548  0.    ]\n",
      " [-1.7793 -4.6589  0.     -3.9461 -0.2711]\n",
      " [-0.6958 -2.1182 -4.5971 -2.1131 -0.8397]\n",
      " [ 0.     -0.6822 -1.7264 -1.2259 -0.8183]]\n",
      "k= 15\n",
      "[[-1.0593 -1.3145 -1.5743 -0.3025  1.3833]\n",
      " [-1.3715 -2.3247 -4.3302 -0.9608  0.    ]\n",
      " [-1.7886 -4.6741  0.     -3.957  -0.2762]\n",
      " [-0.706  -2.1268 -4.6109 -2.1218 -0.854 ]\n",
      " [ 0.     -0.6919 -1.7347 -1.2421 -0.8262]]\n",
      "k= 16\n",
      "[[-1.0744 -1.3222 -1.5859 -0.3071  1.379 ]\n",
      " [-1.3793 -2.3381 -4.338  -0.9679  0.    ]\n",
      " [-1.8004 -4.6828  0.     -3.9632 -0.2829]\n",
      " [-0.7108 -2.1366 -4.6188 -2.1328 -0.8598]\n",
      " [ 0.     -0.6964 -1.7453 -1.2487 -0.8384]]\n",
      "k= 17\n",
      "[[-1.0806 -1.3329 -1.5913 -0.3133  1.3771]\n",
      " [-1.3901 -2.3445 -4.346  -0.9717  0.    ]\n",
      " [-1.8061 -4.6916  0.     -3.9694 -0.2861]\n",
      " [-0.7165 -2.1418 -4.6267 -2.1381 -0.8678]\n",
      " [ 0.     -0.7018 -1.7504 -1.2577 -0.8434]]\n",
      "k= 18\n",
      "[[-1.0892 -1.3377 -1.5979 -0.3162  1.3747]\n",
      " [-1.395  -2.3521 -4.3507 -0.9757  0.    ]\n",
      " [-1.8129 -4.6968  0.     -3.9731 -0.2899]\n",
      " [-0.7194 -2.1473 -4.6314 -2.1443 -0.8714]\n",
      " [ 0.     -0.7046 -1.7563 -1.2618 -0.8502]]\n",
      "k= 19\n",
      "[[-1.0931 -1.3438 -1.6012 -0.3197  1.3735]\n",
      " [-1.4011 -2.356  -4.3553 -0.978   0.    ]\n",
      " [-1.8163 -4.7018  0.     -3.9766 -0.2918]\n",
      " [-0.7227 -2.1504 -4.6359 -2.1475 -0.8759]\n",
      " [ 0.     -0.7076 -1.7594 -1.2669 -0.8533]]\n",
      "k= 20\n",
      "[[-1.098  -1.3468 -1.605  -0.3215  1.3721]\n",
      " [-1.4041 -2.3604 -4.3581 -0.9803  0.    ]\n",
      " [-1.8202 -4.7049  0.     -3.9788 -0.294 ]\n",
      " [-0.7245 -2.1536 -4.6387 -2.151  -0.878 ]\n",
      " [ 0.     -0.7093 -1.7628 -1.2694 -0.8571]]\n",
      "k= 21\n",
      "[[-1.1003 -1.3502 -1.607  -0.3235  1.3714]\n",
      " [-1.4076 -2.3628 -4.3608 -0.9817  0.    ]\n",
      " [-1.8223 -4.7078  0.     -3.9808 -0.2952]\n",
      " [-0.7263 -2.1555 -4.6412 -2.153  -0.8806]\n",
      " [ 0.     -0.711  -1.7646 -1.2722 -0.859 ]]\n",
      "k= 22\n",
      "[[-1.1031 -1.352  -1.6092 -0.3246  1.3706]\n",
      " [-1.4094 -2.3653 -4.3625 -0.983   0.    ]\n",
      " [-1.8245 -4.7097  0.     -3.9821 -0.2964]\n",
      " [-0.7274 -2.1573 -4.6429 -2.155  -0.8819]\n",
      " [ 0.     -0.712  -1.7665 -1.2738 -0.8611]]\n",
      "k= 23\n",
      "[[-1.1046 -1.354  -1.6104 -0.3258  1.3702]\n",
      " [-1.4114 -2.3667 -4.364  -0.9838  0.    ]\n",
      " [-1.8257 -4.7113  0.     -3.9833 -0.2971]\n",
      " [-0.7285 -2.1584 -4.6443 -2.1561 -0.8833]\n",
      " [ 0.     -0.713  -1.7676 -1.2754 -0.8623]]\n",
      "k= 24\n",
      "[[-1.1062 -1.3551 -1.6117 -0.3264  1.3697]\n",
      " [-1.4125 -2.3682 -4.365  -0.9846  0.    ]\n",
      " [-1.827  -4.7124  0.     -3.9841 -0.2978]\n",
      " [-0.7291 -2.1594 -4.6453 -2.1573 -0.8841]\n",
      " [ 0.     -0.7136 -1.7687 -1.2763 -0.8635]]\n",
      "k= 25\n",
      "[[-1.1071 -1.3563 -1.6124 -0.3271  1.3694]\n",
      " [-1.4137 -2.369  -4.3659 -0.9851  0.    ]\n",
      " [-1.8278 -4.7134  0.     -3.9847 -0.2982]\n",
      " [-0.7297 -2.1601 -4.6461 -2.158  -0.8849]\n",
      " [ 0.     -0.7142 -1.7694 -1.2772 -0.8642]]\n",
      "k= 26\n",
      "[[-1.108  -1.3569 -1.6131 -0.3275  1.3692]\n",
      " [-1.4144 -2.3699 -4.3665 -0.9855  0.    ]\n",
      " [-1.8285 -4.7141  0.     -3.9852 -0.2986]\n",
      " [-0.7301 -2.1607 -4.6467 -2.1586 -0.8854]\n",
      " [ 0.     -0.7145 -1.77   -1.2777 -0.8649]]\n",
      "k= 27\n",
      "[[-1.1085 -1.3576 -1.6136 -0.3279  1.369 ]\n",
      " [-1.415  -2.3704 -4.367  -0.9858  0.    ]\n",
      " [-1.8289 -4.7146  0.     -3.9856 -0.2988]\n",
      " [-0.7304 -2.1611 -4.6472 -2.159  -0.8859]\n",
      " [ 0.     -0.7149 -1.7704 -1.2783 -0.8653]]\n",
      "k= 28\n",
      "[[-1.109  -1.358  -1.614  -0.3281  1.3689]\n",
      " [-1.4154 -2.3708 -4.3674 -0.9861  0.    ]\n",
      " [-1.8294 -4.715   0.     -3.9859 -0.2991]\n",
      " [-0.7307 -2.1614 -4.6475 -2.1594 -0.8862]\n",
      " [ 0.     -0.7151 -1.7707 -1.2786 -0.8657]]\n",
      "k= 29\n",
      "[[-1.1094 -1.3584 -1.6143 -0.3283  1.3688]\n",
      " [-1.4158 -2.3712 -4.3677 -0.9863  0.    ]\n",
      " [-1.8296 -4.7153  0.     -3.9861 -0.2992]\n",
      " [-0.7309 -2.1617 -4.6478 -2.1596 -0.8864]\n",
      " [ 0.     -0.7152 -1.771  -1.2789 -0.8659]]\n",
      "k= 30\n",
      "[[-1.1097 -1.3586 -1.6145 -0.3285  1.3687]\n",
      " [-1.416  -2.3714 -4.3679 -0.9864  0.    ]\n",
      " [-1.8299 -4.7156  0.     -3.9862 -0.2993]\n",
      " [-0.731  -2.1619 -4.648  -2.1598 -0.8866]\n",
      " [ 0.     -0.7154 -1.7712 -1.2791 -0.8661]]\n",
      "k= 31\n",
      "[[-1.1099 -1.3588 -1.6147 -0.3286  1.3686]\n",
      " [-1.4163 -2.3716 -4.368  -0.9865  0.    ]\n",
      " [-1.83   -4.7157  0.     -3.9864 -0.2994]\n",
      " [-0.7311 -2.162  -4.6482 -2.16   -0.8867]\n",
      " [ 0.     -0.7155 -1.7713 -1.2792 -0.8663]]\n",
      "k= 32\n",
      "[[-1.11   -1.359  -1.6148 -0.3287  1.3686]\n",
      " [-1.4164 -2.3718 -4.3682 -0.9866  0.    ]\n",
      " [-1.8302 -4.7159  0.     -3.9865 -0.2995]\n",
      " [-0.7312 -2.1621 -4.6483 -2.1601 -0.8868]\n",
      " [ 0.     -0.7155 -1.7714 -1.2794 -0.8664]]\n",
      "k= 33\n",
      "[[-1.1101 -1.3591 -1.6149 -0.3288  1.3685]\n",
      " [-1.4165 -2.3719 -4.3683 -0.9867  0.    ]\n",
      " [-1.8303 -4.716   0.     -3.9865 -0.2995]\n",
      " [-0.7313 -2.1622 -4.6484 -2.1602 -0.8869]\n",
      " [ 0.     -0.7156 -1.7715 -1.2794 -0.8665]]\n",
      "k= 34\n",
      "[[-1.1102 -1.3592 -1.615  -0.3288  1.3685]\n",
      " [-1.4166 -2.372  -4.3683 -0.9867  0.    ]\n",
      " [-1.8303 -4.7161  0.     -3.9866 -0.2996]\n",
      " [-0.7313 -2.1623 -4.6485 -2.1603 -0.887 ]\n",
      " [ 0.     -0.7157 -1.7716 -1.2795 -0.8666]]\n",
      "k= 35\n",
      "[[-1.1103 -1.3592 -1.615  -0.3288  1.3685]\n",
      " [-1.4167 -2.372  -4.3684 -0.9867  0.    ]\n",
      " [-1.8304 -4.7161  0.     -3.9866 -0.2996]\n",
      " [-0.7314 -2.1623 -4.6485 -2.1603 -0.887 ]\n",
      " [ 0.     -0.7157 -1.7716 -1.2796 -0.8666]]\n",
      "k= 36\n",
      "[[-1.1104 -1.3593 -1.6151 -0.3289  1.3685]\n",
      " [-1.4167 -2.3721 -4.3684 -0.9868  0.    ]\n",
      " [-1.8304 -4.7162  0.     -3.9867 -0.2996]\n",
      " [-0.7314 -2.1623 -4.6486 -2.1604 -0.8871]\n",
      " [ 0.     -0.7157 -1.7717 -1.2796 -0.8666]]\n",
      "k= 37\n",
      "[[-1.1104 -1.3593 -1.6151 -0.3289  1.3684]\n",
      " [-1.4168 -2.3721 -4.3685 -0.9868  0.    ]\n",
      " [-1.8305 -4.7162  0.     -3.9867 -0.2997]\n",
      " [-0.7314 -2.1624 -4.6486 -2.1604 -0.8871]\n",
      " [ 0.     -0.7157 -1.7717 -1.2796 -0.8667]]\n",
      "k= 38\n",
      "[[-1.1104 -1.3594 -1.6151 -0.3289  1.3684]\n",
      " [-1.4168 -2.3722 -4.3685 -0.9868  0.    ]\n",
      " [-1.8305 -4.7162  0.     -3.9867 -0.2997]\n",
      " [-0.7314 -2.1624 -4.6486 -2.1604 -0.8871]\n",
      " [ 0.     -0.7158 -1.7717 -1.2797 -0.8667]]\n",
      "k= 39\n",
      "[[-1.1105 -1.3594 -1.6151 -0.3289  1.3684]\n",
      " [-1.4168 -2.3722 -4.3685 -0.9868  0.    ]\n",
      " [-1.8305 -4.7163  0.     -3.9867 -0.2997]\n",
      " [-0.7314 -2.1624 -4.6486 -2.1604 -0.8871]\n",
      " [ 0.     -0.7158 -1.7717 -1.2797 -0.8667]]\n",
      "k= 40\n",
      "[[-1.1105 -1.3594 -1.6152 -0.3289  1.3684]\n",
      " [-1.4168 -2.3722 -4.3685 -0.9868  0.    ]\n",
      " [-1.8305 -4.7163  0.     -3.9867 -0.2997]\n",
      " [-0.7314 -2.1624 -4.6486 -2.1604 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8667]]\n",
      "k= 41\n",
      "[[-1.1105 -1.3594 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3722 -4.3685 -0.9868  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9867 -0.2997]\n",
      " [-0.7315 -2.1624 -4.6486 -2.1604 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8667]]\n",
      "k= 42\n",
      "[[-1.1105 -1.3594 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3722 -4.3686 -0.9868  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9867 -0.2997]\n",
      " [-0.7315 -2.1624 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "k= 43\n",
      "[[-1.1105 -1.3594 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3722 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1624 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "k= 44\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3722 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1624 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "k= 45\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3722 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1624 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "k= 46\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3722 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1624 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "k= 47\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3722 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1625 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "k= 48\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3723 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1625 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "k= 49\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3723 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1625 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "k= 50\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3723 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1625 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "k= 51\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3723 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1625 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# 定义奖励\n",
    "def reward(s):\n",
    "    if s == 20:  # 到充电站\n",
    "        return 1\n",
    "    elif s == 12:  # 到陷阱中\n",
    "        return -10\n",
    "    elif s == 9:  # 到垃圾处\n",
    "        return 3\n",
    "    else:\n",
    "        return 0  # 其他\n",
    "    # in表示0是[*，*，*]中的一个\n",
    "\n",
    "\n",
    "def getAction(a):\n",
    "    if a == 'n':\n",
    "        return 0\n",
    "    elif a == 'e':\n",
    "        return 1\n",
    "    elif a == 's':\n",
    "        return 2\n",
    "    elif a == 'w':\n",
    "        return 3\n",
    "\n",
    "\n",
    "# 在s状态下执行动作a，返回下一状态（编号）\n",
    "def next_states(s, a):\n",
    "    # 越过边界时pass\n",
    "    if (s < world_w and a == 'n') \\\n",
    "            or (s % world_w == 0 and a == 'w') \\\n",
    "            or (s > length - world_w - 1 and a == 's') \\\n",
    "            or ((s + 1) % world_w == 0 and a == 'e'):  # (s % (world_w - 1) == 0 and a == 'e' and s != 0)\n",
    "        next_state = s  # 表现为next_state不变\n",
    "    else:\n",
    "        next_state = s + ds_action[a]  # 进入下一个状态\n",
    "    return next_state\n",
    "\n",
    "\n",
    "# 在s状态下执行动作，返回所有可能的下一状态（编号）list\n",
    "def getsuccessor(s):\n",
    "    successor = []\n",
    "    for a in action:  # 遍历四个动作\n",
    "        if s == next_states(s, a):\n",
    "            continue\n",
    "        else:\n",
    "            next = next_states(s, a)  # 得到下一个状态（编号）\n",
    "        successor.append(next)  # 以list保存当前状态s下执行四个动作的下一状态\n",
    "    return successor\n",
    "\n",
    "\n",
    "def initPolicy():\n",
    "    for s in range(length):\n",
    "        for a in action:\n",
    "            if next_states(s, a) == s:\n",
    "                continue\n",
    "            newAction = getAction(a)\n",
    "            policy[s][newAction] = 1 / len(getsuccessor(s))\n",
    "\n",
    "def policy_eval(theta=0.000001):\n",
    "    V = np.zeros(length)  # 初始化状态值函数列表\n",
    "    Value = np.zeros(length)\n",
    "    iter = 0\n",
    "    while True:\n",
    "        delta = 0  # 定义最大差值，判断是否有进行更新\n",
    "        for s in [20, 21, 22, 23, 24, 15, 16, 17, 18, 19, 10, 11, 12, 13, 14, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4]:  # 遍历所有状态 [0~25]\n",
    "            if s in [9, 20, 12]:  # 若当前状态为吸入状态，则直接pass不做操作\n",
    "                continue\n",
    "            v = 0  # 针对每个状态值函数进行计算\n",
    "            for a in action:\n",
    "                newAction = getAction(a)\n",
    "                next_state = next_states(s, a)\n",
    "                rewards = reward(next_state)\n",
    "                if next_state == 12:\n",
    "                    v += policy[s][newAction] * (rewards + gamma * V[s])\n",
    "                    # print(\" %.2f*(%d+%.1f*%.3f)+\" % (policy[s][newAction], rewards, gamma, V[next_state]), end=\"\")\n",
    "                else:\n",
    "                    v += policy[s][newAction] * (rewards + gamma * V[next_state])\n",
    "            delta = max(delta, np.abs(v - V[s]))  # 更新差值\n",
    "            Value[s] = v  # 存储(更新)每个状态下的状态值函数，即伪代码中的 v <- V(s)\n",
    "        value = np.array(Value).reshape(world_h, world_w)\n",
    "        iter += 1\n",
    "        print('k=', iter)  # 打印迭代次数\n",
    "        print(np.round(value, decimals=4))\n",
    "        if delta < theta:  # 策略评估的迭代次数不能太多，否则状态值函数的数值会越来越大（即使算法仍然在收敛）\n",
    "            break\n",
    "        V = Value.copy()\n",
    "    return V  # 一轮迭代结束后，状态值函数暂时固定\n",
    "\n",
    "\n",
    "def Caculate_Q(s, V, discount_factor=0.8):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        A vector of length env.nA containing the expected value of each action.\n",
    "    \"\"\"\n",
    "    Q = np.zeros((length, 4))\n",
    "    for a in action:  # 遍历能走的动作\n",
    "        next_state = next_states(s, a)\n",
    "        if next_state == s:  # 碰壁\n",
    "            continue\n",
    "        rewards = reward(next_state)\n",
    "        numberA = getAction(a)\n",
    "        Q[s][numberA] = rewards + discount_factor * V[next_state]\n",
    "        print(\"Q[%s][%s]  %.2f = %s + 0.8 * %.2f:\" % (s, a, Q[s][numberA], rewards, V[next_state]))\n",
    "    return Q\n",
    "\n",
    "\n",
    "world_h = 5\n",
    "world_w = 5\n",
    "length = world_h * world_w\n",
    "gamma = 0.8\n",
    "state = [i for i in range(length)]  # 状态（编号）\n",
    "action = ['n', 'e', 's', 'w']  # 动作名称\n",
    "ds_action = {'n': -world_w, 'e': 1, 's': world_w, 'w': -1}\n",
    "value = [0 for i in range(length)]  # 初始化状态值函数，均为0.  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "policy = np.zeros([length, len(action)])\n",
    "\n",
    "\n",
    "def main():\n",
    "    initPolicy()\n",
    "    value = policy_eval()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 基于状态值函数的策略迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;基于状态值函数的策略迭代算法主要包括以下3个阶段：<br>\n",
    "（1）初始化策略函数$\\pi(a|s)$和状态值函数$V_0(s)$<br>\n",
    "（2）策略评估：在当前策略$\\pi$下，使用贝尔曼方程更新状态值函数$V_\\iota(s)$，直到收敛于$v_\\pi(s)$，在根据公式$q_\\pi(s,a)=\\sum p(s',r|s,a)[r+\\Delta v_\\pi(s')]$计算出$q_\\pi(s,a)$<br>\n",
    "（3）策略改进：基于$q_\\pi(s,a)$，通过贪心策略得到更优策略$\\pi'$。<br>\n",
    "<center><img src='./第四章图片/图4.8.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**例4.3** 将基于状态值函数的策略迭代算法4.3应用于例4.1的确定环境扫地机器人任务中，经过多轮迭代后，得到如下表所示的值函数和策略迭代更新过程。\n",
    "<center><img src='./第四章图片/图4.9.png' width='700'></center>\n",
    "<center>面向确定环境扫地机器人任务的状态值函数策略迭代更新过程</center>\n",
    "可以得到如下状态值函数及策略迭代更新图：\n",
    "<center><img src='./第四章图片/图4.10.png' width='500'></center>\n",
    "<center>面向确定环境扫地机器人任务的状态值函数及策略迭代更新图</center>\n",
    "$emsp;$emsp;在上图中，左边一列给出了每一轮（l=0,1,2,3,4,5）状态值函数的迭代更新过程。当l=4和5时，策略不再发生变化（这里状态值也不再变化），策略评估迭代收敛。右侧一列给出了相应的策略改进过程。一句对动作值函数的贪心，获得较好策略，对策略进行改进。由上图可以看出，每个状态的最优策略始终选择动作值最大的动作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数 1\n",
      "Q[1][0]  -1.729965 = 0 + 0.8 * -2.16:\n",
      "Q[1][2]  1.000000 = 1 + 0.8 * 0.00:\n",
      "Q[1][3]  -1.417435 = 0 + 0.8 * -1.77:\n",
      "Q[2][0]  -3.718945 = 0 + 0.8 * -4.65:\n",
      "Q[2][2]  -0.572640 = 0 + 0.8 * -0.72:\n",
      "Q[2][3]  -1.023796 = 0 + 0.8 * -1.28:\n",
      "Q[3][0]  -1.728382 = 0 + 0.8 * -2.16:\n",
      "Q[3][2]  -1.417435 = 0 + 0.8 * -1.77:\n",
      "Q[3][3]  -0.693420 = 0 + 0.8 * -0.87:\n",
      "Q[4][0]  -0.709755 = 0 + 0.8 * -0.89:\n",
      "Q[4][2]  -1.023796 = 0 + 0.8 * -1.28:\n",
      "Q[5][0]  -1.464471 = 0 + 0.8 * -1.83:\n",
      "Q[5][1]  1.000000 = 1 + 0.8 * 0.00:\n",
      "Q[5][3]  -1.729965 = 0 + 0.8 * -2.16:\n",
      "Q[6][0]  -3.773060 = 0 + 0.8 * -4.72:\n",
      "Q[6][1]  -0.572640 = 0 + 0.8 * -0.72:\n",
      "Q[6][2]  -0.585183 = 0 + 0.8 * -0.73:\n",
      "Q[6][3]  -3.718945 = 0 + 0.8 * -4.65:\n",
      "Q[7][0]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[7][1]  -1.417435 = 0 + 0.8 * -1.77:\n",
      "Q[7][2]  -1.729965 = 0 + 0.8 * -2.16:\n",
      "Q[7][3]  -1.728382 = 0 + 0.8 * -2.16:\n",
      "Q[8][0]  -3.189413 = 0 + 0.8 * -3.99:\n",
      "Q[8][1]  -1.023796 = 0 + 0.8 * -1.28:\n",
      "Q[8][2]  -3.718945 = 0 + 0.8 * -4.65:\n",
      "Q[8][3]  -0.709755 = 0 + 0.8 * -0.89:\n",
      "Q[9][0]  -0.239778 = 0 + 0.8 * -0.30:\n",
      "Q[9][1]  -0.693420 = 0 + 0.8 * -0.87:\n",
      "Q[9][2]  -1.728382 = 0 + 0.8 * -2.16:\n",
      "Q[10][0]  -1.133524 = 0 + 0.8 * -1.42:\n",
      "Q[10][1]  -0.585183 = 0 + 0.8 * -0.73:\n",
      "Q[10][3]  -3.773060 = 0 + 0.8 * -4.72:\n",
      "Q[11][0]  -1.897805 = 0 + 0.8 * -2.37:\n",
      "Q[11][1]  -1.729965 = 0 + 0.8 * -2.16:\n",
      "Q[11][2]  -1.464471 = 0 + 0.8 * -1.83:\n",
      "Q[11][3]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[13][0]  -0.789492 = 0 + 0.8 * -0.99:\n",
      "Q[13][1]  -1.728382 = 0 + 0.8 * -2.16:\n",
      "Q[13][2]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[13][3]  -0.239778 = 0 + 0.8 * -0.30:\n",
      "Q[14][0]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[14][1]  -0.709755 = 0 + 0.8 * -0.89:\n",
      "Q[14][2]  -3.189413 = 0 + 0.8 * -3.99:\n",
      "Q[15][0]  -0.888440 = 0 + 0.8 * -1.11:\n",
      "Q[15][1]  -1.464471 = 0 + 0.8 * -1.83:\n",
      "Q[15][3]  -1.897805 = 0 + 0.8 * -2.37:\n",
      "Q[16][0]  -1.087576 = 0 + 0.8 * -1.36:\n",
      "Q[16][1]  -3.773060 = 0 + 0.8 * -4.72:\n",
      "Q[16][2]  -1.133524 = 0 + 0.8 * -1.42:\n",
      "Q[16][3]  -3.494866 = 0 + 0.8 * -4.37:\n",
      "Q[17][0]  -1.292166 = 0 + 0.8 * -1.62:\n",
      "Q[17][1]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[17][2]  -1.897805 = 0 + 0.8 * -2.37:\n",
      "Q[17][3]  -0.789492 = 0 + 0.8 * -0.99:\n",
      "Q[18][0]  -0.263182 = 0 + 0.8 * -0.33:\n",
      "Q[18][1]  -3.189413 = 0 + 0.8 * -3.99:\n",
      "Q[18][2]  -3.494866 = 0 + 0.8 * -4.37:\n",
      "Q[18][3]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[20][1]  -1.133524 = 0 + 0.8 * -1.42:\n",
      "Q[20][3]  -1.087576 = 0 + 0.8 * -1.36:\n",
      "Q[21][1]  -1.897805 = 0 + 0.8 * -2.37:\n",
      "Q[21][2]  -0.888440 = 0 + 0.8 * -1.11:\n",
      "Q[21][3]  -1.292166 = 0 + 0.8 * -1.62:\n",
      "Q[22][1]  -3.494866 = 0 + 0.8 * -4.37:\n",
      "Q[22][2]  -1.087576 = 0 + 0.8 * -1.36:\n",
      "Q[22][3]  -0.263182 = 0 + 0.8 * -0.33:\n",
      "Q[23][1]  -0.789492 = 0 + 0.8 * -0.99:\n",
      "Q[23][2]  -1.292166 = 0 + 0.8 * -1.62:\n",
      "Q[23][3]  1.094727 = 0 + 0.8 * 1.37:\n",
      "Q[24][1]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[24][2]  -0.263182 = 0 + 0.8 * -0.33:\n",
      "[[-1.1105 -1.3595 -1.6152 -0.329   1.3684]\n",
      " [-1.4169 -2.3723 -4.3686 -0.9869  0.    ]\n",
      " [-1.8306 -4.7163  0.     -3.9868 -0.2997]\n",
      " [-0.7315 -2.1625 -4.6487 -2.1605 -0.8872]\n",
      " [ 0.     -0.7158 -1.7718 -1.2797 -0.8668]]\n",
      "****************************************************************************************************\n",
      "迭代次数 2\n",
      "Q[1][0]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[1][2]  1.000000 = 1 + 0.8 * 0.00:\n",
      "Q[1][3]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[2][0]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[2][2]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[2][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[3][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[3][2]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[3][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[4][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[4][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[5][0]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[5][1]  1.000000 = 1 + 0.8 * 0.00:\n",
      "Q[5][3]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[6][0]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[6][1]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[6][2]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[6][3]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[7][0]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[7][1]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[7][2]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[7][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[8][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[8][1]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[8][2]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[8][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[9][0]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[9][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[9][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[10][0]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[10][1]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[10][3]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[11][0]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[11][1]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[11][2]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[11][3]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[13][0]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[13][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[13][2]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[13][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[14][0]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[14][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[14][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[15][0]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[15][1]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[15][3]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[16][0]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[16][1]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[16][2]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[16][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[17][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[17][1]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[17][2]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[17][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[18][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][3]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[20][1]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[20][3]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[21][1]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[21][2]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[21][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[22][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[22][2]  0.000000 = 0 + 0.8 * 0.00:\n",
      "Q[22][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[23][1]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[23][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[23][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[24][1]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[24][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "[[0.    0.    1.92  2.4   3.   ]\n",
      " [0.    0.    2.4   3.    0.   ]\n",
      " [0.8   0.64  0.    2.4   3.   ]\n",
      " [1.    0.8   0.64  1.92  2.4  ]\n",
      " [0.    1.    0.8   1.536 1.92 ]]\n",
      "****************************************************************************************************\n",
      "迭代次数 3\n",
      "Q[1][0]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[1][2]  1.000000 = 1 + 0.8 * 0.00:\n",
      "Q[1][3]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[2][0]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[2][2]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[2][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[3][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[3][2]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[3][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[4][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[4][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[5][0]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[5][1]  1.000000 = 1 + 0.8 * 0.00:\n",
      "Q[5][3]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[6][0]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[6][1]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[6][2]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[6][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[7][0]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[7][1]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[7][2]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[7][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[8][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[8][1]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[8][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[8][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[9][0]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[9][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[9][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[10][0]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[10][1]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[10][3]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[11][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[11][1]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[11][2]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[11][3]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[13][0]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[13][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[13][2]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[13][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[14][0]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[14][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[14][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[15][0]  0.409600 = 0 + 0.8 * 0.51:\n",
      "Q[15][1]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[15][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[16][0]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[16][1]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[16][2]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[16][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[17][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[17][1]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[17][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[17][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[18][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][3]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[20][1]  0.512000 = 0 + 0.8 * 0.64:\n",
      "Q[20][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[21][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[21][2]  0.409600 = 0 + 0.8 * 0.51:\n",
      "Q[21][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[22][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[22][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[22][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[23][1]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[23][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[23][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[24][1]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[24][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "[[0.512  1.536  1.92   2.4    3.    ]\n",
      " [0.64   1.92   2.4    3.     0.    ]\n",
      " [0.8    0.64   0.     2.4    3.    ]\n",
      " [1.     0.8    1.536  1.92   2.4   ]\n",
      " [0.     1.     1.2288 1.536  1.92  ]]\n",
      "****************************************************************************************************\n",
      "迭代次数 4\n",
      "Q[1][0]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[1][2]  1.000000 = 1 + 0.8 * 0.00:\n",
      "Q[1][3]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[2][0]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[2][2]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[2][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[3][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[3][2]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[3][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[4][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[4][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[5][0]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[5][1]  1.000000 = 1 + 0.8 * 0.00:\n",
      "Q[5][3]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[6][0]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[6][1]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[6][2]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[6][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[7][0]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[7][1]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[7][2]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[7][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[8][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[8][1]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[8][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[8][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[9][0]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[9][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[9][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[10][0]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[10][1]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[10][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[11][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[11][1]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[11][2]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[11][3]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[13][0]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[13][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[13][2]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[13][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[14][0]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[14][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[14][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[15][0]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[15][1]  0.640000 = 0 + 0.8 * 0.80:\n",
      "Q[15][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[16][0]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[16][1]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[16][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[16][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[17][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[17][1]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[17][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[17][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[18][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][3]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[20][1]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[20][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[21][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[21][2]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[21][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[22][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[22][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[22][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[23][1]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[23][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[23][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[24][1]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[24][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "[[1.2288 1.536  1.92   2.4    3.    ]\n",
      " [1.536  1.92   2.4    3.     0.    ]\n",
      " [0.8    1.536  0.     2.4    3.    ]\n",
      " [1.     1.2288 1.536  1.92   2.4   ]\n",
      " [0.     1.     1.2288 1.536  1.92  ]]\n",
      "****************************************************************************************************\n",
      "迭代次数 5\n",
      "Q[1][0]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[1][2]  1.000000 = 1 + 0.8 * 0.00:\n",
      "Q[1][3]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[2][0]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[2][2]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[2][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[3][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[3][2]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[3][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[4][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[4][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[5][0]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[5][1]  1.000000 = 1 + 0.8 * 0.00:\n",
      "Q[5][3]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[6][0]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[6][1]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[6][2]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[6][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[7][0]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[7][1]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[7][2]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[7][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[8][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[8][1]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[8][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[8][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[9][0]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[9][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[9][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[10][0]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[10][1]  0.800000 = 0 + 0.8 * 1.00:\n",
      "Q[10][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[11][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[11][1]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[11][2]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[11][3]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[13][0]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[13][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[13][2]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[13][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[14][0]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[14][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[14][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[15][0]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[15][1]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[15][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[16][0]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[16][1]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[16][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[16][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[17][0]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[17][1]  -10.000000 = -10 + 0.8 * 0.00:\n",
      "Q[17][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[17][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[18][0]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[18][3]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[20][1]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[20][3]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[21][1]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[21][2]  0.983040 = 0 + 0.8 * 1.23:\n",
      "Q[21][3]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[22][1]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[22][2]  1.228800 = 0 + 0.8 * 1.54:\n",
      "Q[22][3]  1.920000 = 0 + 0.8 * 2.40:\n",
      "Q[23][1]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[23][2]  1.536000 = 0 + 0.8 * 1.92:\n",
      "Q[23][3]  2.400000 = 0 + 0.8 * 3.00:\n",
      "Q[24][1]  3.000000 = 3 + 0.8 * 0.00:\n",
      "Q[24][2]  1.920000 = 0 + 0.8 * 2.40:\n",
      "[[1.2288 1.536  1.92   2.4    3.    ]\n",
      " [1.536  1.92   2.4    3.     0.    ]\n",
      " [1.2288 1.536  0.     2.4    3.    ]\n",
      " [1.     1.2288 1.536  1.92   2.4   ]\n",
      " [0.     1.     1.2288 1.536  1.92  ]]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def reward(s):\n",
    "    if s == 20:  # 到充电站\n",
    "        return 1\n",
    "    elif s == 12:  # 到陷阱中\n",
    "        return -10\n",
    "    elif s == 9:  # 到垃圾处\n",
    "        return 3\n",
    "    else:\n",
    "        return 0  # 其他\n",
    "\n",
    "\n",
    "def getAction(a):\n",
    "    if a == 'n':\n",
    "        return 0\n",
    "    elif a == 'e':\n",
    "        return 3\n",
    "    elif a == 's':\n",
    "        return 1\n",
    "    elif a == 'w':\n",
    "        return 2\n",
    "\n",
    "# 在s状态下执行动作a，返回下一状态（编号）\n",
    "def next_states(s, a):\n",
    "    # 越过边界时pass\n",
    "    if (s < world_w and a == 'n') \\\n",
    "            or (s % world_w == 0 and a == 'w') \\\n",
    "            or (s > length - world_w - 1 and a == 's') \\\n",
    "            or ((s + 1) % world_w == 0 and a == 'e'):  # (s % (world_w - 1) == 0 and a == 'e' and s != 0)\n",
    "        next_state = s  # 表现为next_state不变\n",
    "    else:\n",
    "        next_state = s + ds_action[a]  # 进入下一个状态\n",
    "    return next_state\n",
    "\n",
    "\n",
    "# 在s状态下执行动作，返回所有可能的下一状态（编号）list\n",
    "def getsuccessor(s):\n",
    "    successor = []\n",
    "    for a in action:  # 遍历四个动作\n",
    "        if s == next_states(s, a):\n",
    "            continue\n",
    "        else:\n",
    "            # print(\"状态s=%s,动作a=%s\"%(s,a))\n",
    "            next = next_states(s, a)  # 得到下一个状态（编号）\n",
    "        successor.append(next)  # 以list保存当前状态s下执行四个动作的下一状态\n",
    "    return successor\n",
    "\n",
    "\n",
    "def initPolicy():\n",
    "    for s in range(length):\n",
    "        if s == 9 or s == 12 or s == 20:\n",
    "            continue\n",
    "        for a in action:\n",
    "            if next_states(s, a) == s:\n",
    "                continue\n",
    "            newAction = getAction(a)\n",
    "            policy[s][newAction] = 1 / len(getsuccessor(s))\n",
    "\n",
    "\n",
    "def policy_eval(theta=0.000001):\n",
    "    V = np.zeros(length)  # 初始化状态值函数列表\n",
    "    while True:\n",
    "        delta = 0  # 定义最大差值，判断是否有进行更新\n",
    "\n",
    "        for s in [20, 21, 22, 23, 24, 15, 16, 17, 18, 19, 10, 11, 12, 13, 14, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4]:  # 遍历所有状态 [0~25]\n",
    "            if s in [9, 20, 12]:  # 若当前状态为吸入状态，则直接pass不做操作\n",
    "                continue\n",
    "            v = 0  # 针对每个状态值函数进行计算\n",
    "            for a in action:\n",
    "                newAction = getAction(a)\n",
    "                next_state = next_states(s, a)\n",
    "                rewards = reward(next_state)\n",
    "                if next_state == 12:\n",
    "                    v += policy[s][newAction] * (rewards + gamma * V[s])\n",
    "                else:\n",
    "                    v += policy[s][newAction] * (rewards + gamma * V[next_state])\n",
    "            delta = max(delta, np.abs(v - V[s]))  # 更新差值\n",
    "            V[s] = v  # 存储(更新)每个状态下的状态值函数，即伪代码中的 v <- V(s)\n",
    "\n",
    "        if delta < theta:  # 策略评估的迭代次数不能太多，否则状态值函数的数值会越来越大（即使算法仍然在收敛）\n",
    "            break\n",
    "    return V  # 一轮迭代结束后，状态值函数暂时固定\n",
    "\n",
    "\n",
    "def Caculate_Q(s, V, num, discount_factor=0.8):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        A vector of length env.nA containing the expected value of each action.\n",
    "    \"\"\"\n",
    "    Q = np.zeros((length, 4))\n",
    "    Q[:][:] = -100\n",
    "    for a in action:  # 遍历能走的动作\n",
    "        next_state = next_states(s, a)\n",
    "        if next_state == s:  # 碰壁\n",
    "            continue\n",
    "        rewards = reward(next_state)\n",
    "        numberA = getAction(a)\n",
    "        if s == 12:\n",
    "            Q[s][numberA] = rewards + discount_factor * V[s]\n",
    "        else:\n",
    "            Q[s][numberA] = rewards + discount_factor * V[next_state]\n",
    "        print(\"Q[%s][%d]  %f = %s + 0.8 * %.2f:\" % (num, numberA, Q[s][numberA], rewards, V[next_state]))\n",
    "    return Q\n",
    "\n",
    "\n",
    "def policy_improvement(V, policy):  # 策略改进\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        policy: the optimal policy, a matrix of shape [S, A] where each state s contains a valid probability distribution over actions.\n",
    "        V: the value function for the optimal policy.\n",
    "    \"\"\"\n",
    "    k = -1\n",
    "    policy_stable = True  # Will be set to false if we make any changes to the policy\n",
    "    for s in [20, 21, 22, 23, 24, 15, 16, 17, 18, 19, 10, 11, 12, 13, 14, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4]:\n",
    "        k += 1\n",
    "        if np.all(policy[s] == 0):\n",
    "            continue\n",
    "        old_a = np.argmax(policy[s])  # 记录当前策略在该状态s下所选择的动作 —— 选择概率最高的动作\n",
    "        Q = Caculate_Q(s, V, k)  # 在当前状态和策略下，计算动作值函数 —— 要判断在状态s下选择其他动作的好坏，就需要获得状态s的动作值函数\n",
    "        best_a = np.argmax(Q[s])  # 采用贪婪策略获得状态s的最优动作；如果往两个方向前进都可以得到最优解，会随机选其一\n",
    "        if old_a != best_a:  # 判定策略是否稳定\n",
    "            policy_stable = False  # 动作还在变化，不稳定状态\n",
    "        policy[s] = np.eye(len(action))[best_a]  # 基于贪婪法则更新策略，形如[0，0，1，0]； -》np.eye(*)：构建对角单位阵\n",
    "        # 经过一次策略改进后的策略将不再拥有多个动作可供备选，取而代之的是在某种状态下的确定策略\n",
    "    return V, policy_stable\n",
    "\n",
    "\n",
    "world_h = 5\n",
    "world_w = 5\n",
    "length = world_h * world_w\n",
    "gamma = 0.8\n",
    "state = [i for i in range(length)]  # 状态（编号）\n",
    "action = ['n', 's', 'w', 'e']  # 动作名称\n",
    "ds_action = {'n': -world_w, 'e': 1, 's': world_w, 'w': -1}\n",
    "value = [0 for i in range(length)]  # 初始化状态值函数，均为0.  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "policy = np.zeros([length, len(action)])\n",
    "\n",
    "def Policy_Iterration():\n",
    "    initPolicy()\n",
    "    k = 1\n",
    "    while True:  # Evaluate the current policy\n",
    "        print(\"迭代次数\", k)\n",
    "        V = policy_eval()  # 得到当前策略下的收敛状态值函数 —— 与Value_Iteration的不同点，多了policy_eval()函数。policy会在迭代中改变\n",
    "        V, policy_stable = policy_improvement(V, policy)\n",
    "        v = np.array(V).reshape(world_h, world_w)\n",
    "        policy1 = np.array(policy).reshape(length, len(action))\n",
    "        print(np.round(v, decimals=4))\n",
    "        print(\"*\" * 100)\n",
    "        k += 1\n",
    "        if policy_stable:  # # If the policy is stable we've found an optimal policy. Return it\n",
    "            return policy, V\n",
    "\n",
    "policy, V = Policy_Iterration()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 值迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在策略迭代中，每轮策略改进之前都涉及策略评估，每次策略评估都需要多次遍历才能保证状态值函数在一定程度上得到收敛，这将消耗大量的时间和计算资源。从例 4.1 中可以看出，当$\\tau\\geq 4$时，值函数的变化对策略不再有影响。于是根据迭代次数与策略稳定的相互关系，考虑在单步评估之后就进入改进过程，即采取截断式策略评估，在一次遍历完所有的状态后立即停止策略评估，进行策略改进，这种方法称为值迭代。基于状态值函数的值迭代公式为：\n",
    "\n",
    "\\begin{align}\n",
    "v_\\iota(s) &= \\max \\limits_a \\mathop{\\mathbb{E}}_\\pi(R_{t+1}+\\gamma v_\\pi(S_{t+1})|S_t=s,A_t=a) \\\\\n",
    "        &=\\max \\limits_a \\sum_{s^{'},r}p(s^{'},r|s,a)[r+\\gamma v_{\\iota -1}(s^{'})]   \n",
    "\\end{align}\n",
    "\n",
    "算法4.5给出了在有穷状态空间MDP中，基于状态值函数的值迭代算法。\n",
    "\n",
    "<center><img src='./第四章图片/图4.11.png' width='600'></center>\n",
    "&emsp;&emsp;与策略迭代类似，也可以直接基于动作值函数进行值迭代，迭代公式为：\n",
    "$$ \\mathcal{Q}(s,a)=\\sum_{s^{'},r}p(s^{'},r|s,a)\\left [r+\\gamma\\max_{a^{'}} \\mathcal{Q}(s^{'},a^{'})\\right]$$\n",
    "\n",
    "算法4.6给出了在有穷状态空间MDP中，基于动作值函数的值迭代算法。\n",
    "<center><img src='./第四章图片/图4.12.png' width='600'></center>\n",
    "<center><img src='./第四章图片/图4.13.png' width='600'></center>\n",
    "&emsp;&emsp;算法4.5和算法4.6既可用于确定环境MDP又可用于随机环境MDP。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**例4.4**&ensp;将基于状态值函数的值迭代算法4.5应用于例4.1的确定环境扫地机器人任务中，可以得到以下状态值迭代更新过程：<br>\n",
    "（1）当$l=0$时（$l$为值迭代的次数）,对于所有的$s$初始化为：$V(s)=0$;<br>\n",
    "（2）当$l=1$时,以状态$S_{24}$为例。在策略$\\pi$下，只能采取向下和向左2个动作，概率各为0.5。采取向下的动作时，到达状态$S_{19}(V(S_{23})=0)$，并可以捡到垃圾，获得$r_1=+3$的奖赏；采取向左的动作时，到达状态$S_{23}(V(S_{23})=2.40)$，获得$r_2=0$的奖赏。根据算法4.2计算得：\n",
    "\n",
    "\\begin{align}\n",
    "V(s_{24}) &= \\max (r_1 + \\gamma V(S_{19}),r_2+\\gamma V(S_{23})) \\\\\n",
    "        &=\\max (3+0.8*0,0+0.8*2.40)\\\\\n",
    "        &=\\max (3,1.92) \\\\\n",
    "        &= 3.00\n",
    "\\end{align}\n",
    "\n",
    "同理可以计算状态S_5和S_6的状态值函数：\n",
    "\\begin{align}\n",
    "V(s_{6}) &= \\max (r_1 + \\gamma V(S_{10}),r_2+\\gamma V(S_{0}),r_3+\\gamma V(S_{6})) \\\\\n",
    "        &=\\max (0+0.8*0,1+0.8*0,0+0.8*{0})\\\\\n",
    "        &= 3.00\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "V(s_{6}) &= \\max (r_1 + \\gamma V(S_{11}),r_2+\\gamma V(S_{1}),r_3+\\gamma V(S_{5}),r_4+\\gamma V(S_{7})) \\\\\n",
    "        &=\\max (0+0.8*0,0+0.8*1.00,0+0.8*{1.00},0+0.8*{0})\\\\\n",
    "        &= 0.80\n",
    "\\end{align}\n",
    "\n",
    "按顺序计算完一轮后，得到值函数$V(s)$，如图4.7$(l=1)$所示。<br>\n",
    "\n",
    "（3）当$l=2$时,以状态$S_{22}$、$S_{23}$为例，计算状态值函数。异步计算方式，通常与迭代的计算顺序有关，根据例4.1规定，在每一轮次中，这3个状态的计算顺序为：\n",
    "\n",
    "\\begin{align}\n",
    "V(s_{22})&= \\max (r_1 + \\gamma V(S_{17}),r_2+\\gamma V(S_{21}),r_3+\\gamma V(S_{23})) \\\\\n",
    "        &=\\max (0+0.8*{2.40},0+0.8*{0.41},0+0.8*{2.40})\\\\\n",
    "        &= 1.92\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "V(s_{23})&= \\max (r_1 + \\gamma V(S_{18}),r_2+\\gamma V(S_{22}),r_3+\\gamma V(S_{24})) \\\\\n",
    "        &=\\max (0+0.8*{3.00},0+0.8*{1.92},0+0.8*{3.00})\\\\\n",
    "        &= 3.00\n",
    "\\end{align}\n",
    "\n",
    "按顺序计算完一轮后，得到值函数$V(s)$，如图 4.7（ $l=2$）所示。<br>\n",
    "（4）当$l=6$时，$|v_{l}(s)-v_{l-1}(s)|_{\\infty}<\\theta$，认为v_{l}(s)已经收敛于$v_*(s)$,计算得到的$v_*(s)$就是最优状态值函数。<br>\n",
    "\n",
    "确定环境扫地机器人任务通过状态值迭代得到的结果如下图所示：\n",
    "<center><img src='./第四章图片/图4.14.png' width='600'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "Q[0][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[0][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[1][0]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[1][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[1][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[2][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[2][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[2][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[3][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[3][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[3][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[4][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[4][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[5][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[5][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[5][3]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[6][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[6][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[6][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[6][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[7][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[7][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[7][2]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[7][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[8][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[8][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[8][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[8][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[9][0]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[9][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[9][3]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[10][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[10][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[10][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[11][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[11][1]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[11][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[11][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[12][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[12][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[12][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[12][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[13][0]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[13][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[13][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[13][3]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[14][0]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[14][2]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[14][3]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[15][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[15][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[15][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[16][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[16][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[16][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[16][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[17][0]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[17][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[17][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[17][3]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[18][0]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[18][1]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[18][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[18][3]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[19][0]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][2]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[19][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[20][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[20][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[21][0]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[21][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[21][3]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[22][0]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[22][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[22][3]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[23][0]  0.26 = 0 + 0.8 * 0.33:\n",
      "Q[23][1]  0.00 = 0 + 0.8 * 0.00:\n",
      "Q[23][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[24][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[24][3]  3.00 = 3 + 0.8 * 0.00:\n",
      "k= 1\n",
      "[[0.512  0.4096 0.3277 2.4    3.    ]\n",
      " [0.64   0.512  0.4096 3.     0.    ]\n",
      " [0.8    0.64   0.     0.4096 3.    ]\n",
      " [1.     0.8    0.64   0.512  0.4096]\n",
      " [0.     1.     0.8    0.64   0.512 ]]\n",
      "Q[0][1]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[0][2]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[1][0]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[1][1]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[1][2]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[2][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[2][1]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[2][2]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[3][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[3][1]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[3][2]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[4][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[4][2]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[5][1]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[5][2]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[5][3]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[6][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[6][1]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[6][2]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[6][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[7][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[7][1]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[7][2]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[7][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[8][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[8][1]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[8][2]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[8][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[9][0]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[9][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[9][3]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[10][1]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[10][2]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[10][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[11][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[11][1]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[11][2]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[11][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[12][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[12][1]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[12][2]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[12][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[13][0]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[13][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[13][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[13][3]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[14][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[14][2]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[14][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[15][1]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[15][2]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[15][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[16][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[16][1]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[16][2]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[16][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[17][0]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[17][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[17][2]  0.26 = 0 + 0.8 * 0.33:\n",
      "Q[17][3]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[18][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[18][1]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[18][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[18][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[19][0]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[20][1]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[20][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[21][0]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[21][1]  0.26 = 0 + 0.8 * 0.33:\n",
      "Q[21][3]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[22][0]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[22][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[22][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[23][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[23][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[23][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[24][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[24][3]  3.00 = 3 + 0.8 * 0.00:\n",
      "k= 2\n",
      "[[0.512  0.4096 1.92   2.4    3.    ]\n",
      " [0.64   0.512  2.4    3.     0.    ]\n",
      " [0.8    0.64   0.     2.4    3.    ]\n",
      " [1.     0.8    0.64   0.512  2.4   ]\n",
      " [0.     1.     0.8    0.64   0.512 ]]\n",
      "Q[0][1]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[0][2]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[1][0]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[1][1]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[1][2]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[2][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[2][1]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[2][2]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[3][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[3][1]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[3][2]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[4][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[4][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[5][1]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[5][2]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[5][3]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[6][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[6][1]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[6][2]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[6][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[7][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[7][1]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[7][2]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[7][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[8][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[8][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[8][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[8][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[9][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[9][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[9][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[10][1]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[10][2]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[10][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[11][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[11][1]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[11][2]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[11][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[12][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[12][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[12][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[12][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[13][0]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[13][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[13][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[13][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[14][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[14][2]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[14][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[15][1]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[15][2]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[15][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[16][0]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[16][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[16][2]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[16][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[17][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[17][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[17][2]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[17][3]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[18][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[18][1]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[18][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[18][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[19][0]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[20][1]  0.33 = 0 + 0.8 * 0.41:\n",
      "Q[20][3]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[21][0]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[21][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[21][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[22][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[22][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[22][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[23][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[23][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[23][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[24][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[24][3]  3.00 = 3 + 0.8 * 0.00:\n",
      "k= 3\n",
      "[[0.512 1.536 1.92  2.4   3.   ]\n",
      " [0.64  1.92  2.4   3.    0.   ]\n",
      " [0.8   0.64  0.    2.4   3.   ]\n",
      " [1.    0.8   0.64  1.92  2.4  ]\n",
      " [0.    1.    0.8   0.64  1.92 ]]\n",
      "Q[0][1]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[0][2]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[1][0]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[1][1]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[1][2]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[2][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[2][1]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[2][2]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[3][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[3][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[3][2]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[4][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[4][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[5][1]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[5][2]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[5][3]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[6][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[6][1]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[6][2]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[6][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[7][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[7][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[7][2]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[7][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[8][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[8][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[8][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[8][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[9][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[9][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[9][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[10][1]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[10][2]  0.51 = 0 + 0.8 * 0.64:\n",
      "Q[10][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[11][0]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[11][1]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[11][2]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[11][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[12][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[12][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[12][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[12][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[13][0]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[13][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[13][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[13][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[14][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[14][2]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[14][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[15][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[15][2]  0.41 = 0 + 0.8 * 0.51:\n",
      "Q[15][3]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[16][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[16][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[16][2]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[16][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[17][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[17][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[17][2]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[17][3]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[18][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[18][1]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[18][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[18][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[19][0]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[20][1]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[20][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[21][0]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[21][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[21][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[22][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[22][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[22][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[23][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[23][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[23][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[24][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[24][3]  3.00 = 3 + 0.8 * 0.00:\n",
      "k= 4\n",
      "[[1.2288 1.536  1.92   2.4    3.    ]\n",
      " [1.536  1.92   2.4    3.     0.    ]\n",
      " [0.8    1.536  0.     2.4    3.    ]\n",
      " [1.     0.8    1.536  1.92   2.4   ]\n",
      " [0.     1.     0.8    1.536  1.92  ]]\n",
      "Q[0][1]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[0][2]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[1][0]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[1][1]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[1][2]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[2][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[2][1]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[2][2]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[3][0]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[3][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[3][2]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[4][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[4][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[5][1]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[5][2]  0.64 = 0 + 0.8 * 0.80:\n",
      "Q[5][3]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[6][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[6][1]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[6][2]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[6][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[7][0]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[7][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[7][2]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[7][3]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[8][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[8][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[8][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[8][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[9][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[9][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[9][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[10][1]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[10][2]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[10][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[11][0]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[11][1]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[11][2]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[11][3]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[12][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[12][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[12][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[12][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[13][0]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[13][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[13][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[13][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[14][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[14][2]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[14][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[15][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[15][2]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[15][3]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[16][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[16][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[16][2]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[16][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[17][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[17][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[17][2]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[17][3]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[18][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[18][1]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[18][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[18][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[19][0]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[20][1]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[20][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[21][0]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[21][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[21][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[22][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[22][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[22][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[23][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[23][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[23][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[24][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[24][3]  3.00 = 3 + 0.8 * 0.00:\n",
      "k= 5\n",
      "[[1.2288 1.536  1.92   2.4    3.    ]\n",
      " [1.536  1.92   2.4    3.     0.    ]\n",
      " [1.2288 1.536  0.     2.4    3.    ]\n",
      " [1.     1.2288 1.536  1.92   2.4   ]\n",
      " [0.     1.     1.2288 1.536  1.92  ]]\n",
      "Q[0][1]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[0][2]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[1][0]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[1][1]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[1][2]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[2][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[2][1]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[2][2]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[3][0]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[3][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[3][2]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[4][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[4][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[5][1]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[5][2]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[5][3]  1.00 = 1 + 0.8 * 0.00:\n",
      "Q[6][0]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[6][1]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[6][2]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[6][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[7][0]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[7][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[7][2]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[7][3]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[8][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[8][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[8][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[8][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[9][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[9][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[9][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[10][1]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[10][2]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[10][3]  0.80 = 0 + 0.8 * 1.00:\n",
      "Q[11][0]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[11][1]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[11][2]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[11][3]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[12][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[12][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[12][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[12][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[13][0]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[13][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[13][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[13][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[14][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[14][2]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[14][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[15][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[15][2]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[15][3]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[16][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[16][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[16][2]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[16][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[17][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[17][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[17][2]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[17][3]  -10.00 = -10 + 0.8 * 0.00:\n",
      "Q[18][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[18][1]  3.00 = 3 + 0.8 * 0.00:\n",
      "Q[18][2]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[18][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[19][0]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][2]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[19][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[20][1]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[20][3]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[21][0]  0.98 = 0 + 0.8 * 1.23:\n",
      "Q[21][1]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[21][3]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[22][0]  1.23 = 0 + 0.8 * 1.54:\n",
      "Q[22][1]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[22][3]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[23][0]  1.54 = 0 + 0.8 * 1.92:\n",
      "Q[23][1]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[23][3]  2.40 = 0 + 0.8 * 3.00:\n",
      "Q[24][0]  1.92 = 0 + 0.8 * 2.40:\n",
      "Q[24][3]  3.00 = 3 + 0.8 * 0.00:\n",
      "k= 6\n",
      "[[1.2288 1.536  1.92   2.4    3.    ]\n",
      " [1.536  1.92   2.4    3.     0.    ]\n",
      " [1.2288 1.536  0.     2.4    3.    ]\n",
      " [1.     1.2288 1.536  1.92   2.4   ]\n",
      " [0.     1.     1.2288 1.536  1.92  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义奖励\n",
    "def reward(s):\n",
    "\n",
    "    if s == 20:  # 到充电站\n",
    "        return 1\n",
    "    elif s == 12:  # 到陷阱中\n",
    "        return -10\n",
    "    elif s == 9:  # 到垃圾处\n",
    "        return 3\n",
    "    else:\n",
    "        return 0  # 其他\n",
    "    # in表示0是[*，*，*]中的一个\n",
    "\n",
    "def getAction(a):\n",
    "    if a == 'n':\n",
    "        return 2\n",
    "    elif a == 'e':\n",
    "        return 1\n",
    "    elif a =='s':\n",
    "        return 3\n",
    "    elif a == 'w':\n",
    "        return 0\n",
    "\n",
    "# 在s状态下执行动作a，返回下一状态（编号）\n",
    "def next_states(s, a):\n",
    "    # 越过边界时pass\n",
    "    if (s < world_w and a == 'n') \\\n",
    "            or (s % world_w == 0 and a == 'w') \\\n",
    "            or (s > length - world_w - 1 and a == 's') \\\n",
    "            or ((s + 1) % world_w == 0 and a == 'e'):  # (s % (world_w - 1) == 0 and a == 'e' and s != 0)\n",
    "        next_state = s  # 表现为next_state不变\n",
    "    else:\n",
    "        next_state = s + ds_action[a]  # 进入下一个状态\n",
    "    return next_state\n",
    "\n",
    "\n",
    "# 在s状态下执行动作，返回所有可能的下一状态（编号）list\n",
    "def getsuccessor(s):\n",
    "    successor = []\n",
    "    for a in action:  # 遍历四个动作\n",
    "        if s == next_states(s,a):\n",
    "            continue\n",
    "        else:\n",
    "            # print(\"状态s=%s,动作a=%s\"%(s,a))\n",
    "            next = next_states(s, a)  # 得到下一个状态（编号）\n",
    "        successor.append(next)  # 以list保存当前状态s下执行四个动作的下一状态\n",
    "    # print(len(successor))\n",
    "    return successor\n",
    "\n",
    "\n",
    "# 更新状态值函数\n",
    "def value_update(s,numb):  # 传入当前状态\n",
    "    value_new = 0\n",
    "    if s in [9,20,12]:  # 若当前状态为吸入状态，则直接pass不做操作\n",
    "        pass\n",
    "    else:\n",
    "        Q =[]\n",
    "        successor = getsuccessor(s)  # 得到所有可能的下一状态list\n",
    "        # rewards = reward(s)  # 得到当前状态的奖励\n",
    "        # print(\"s %s=\"%s,end=\"\")\n",
    "        for next_state in successor:  # 遍历所有可能的下一状态\n",
    "            rewards = reward(next_state)\n",
    "            value_new = rewards + gamma * value[next_state]  # 计算公式，得到当前状态的状态价值函数\n",
    "            Q.append(value_new)\n",
    "            # print(\"%.2f*(%d+%.1f*%.2f) = %.2f\"%(1/len(successor),rewards,gamma,value[next_state],value_new))\n",
    "            # 注意前面的1/len(successor)为该s状态能够到下个状态的个数概率，该代码是第一次迭代时的固定策略π(a|s)\n",
    "        value_new = max(Q)\n",
    "        # print(\"第%d个状态最大值：%.2f\"%(numb,value_new))\n",
    "        # print()\n",
    "    return value_new\n",
    "\n",
    "\n",
    "def Caculate_Q(s, V, num,discount_factor=0.8):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        A vector of length env.nA containing the expected value of each action.\n",
    "    \"\"\"\n",
    "    Q = np.zeros((length, 4))\n",
    "    # Q[:][:] = -1000\n",
    "    for a in ['w', 'e', 'n', 's']:  # 遍历能走的动作\n",
    "        # for prob, next_state, reward, done in env.P[s][a]:\n",
    "        #     Q[s][a] += prob * (reward + discount_factor * V[next_state])  # 计算当前状态s下的动作值函数列表 [q1,q2,q3,q4]\n",
    "        next_state = next_states(s,a)\n",
    "        if next_state == s: #碰壁\n",
    "            continue\n",
    "        rewards = reward(next_state)\n",
    "        numberA = getAction(a)\n",
    "        Q[s][numberA]= rewards + discount_factor * V[next_state]\n",
    "        print(\"Q[%s][%d]  %.2f = %s + 0.8 * %.2f:\"%(num,numberA,Q[s][numberA],rewards,V[next_state]))\n",
    "\n",
    "\n",
    "def initial_state():\n",
    "    v = np.array(value).reshape(world_h, world_w)  # 调整初始化状态值函数矩阵\n",
    "    print(v)\n",
    "\n",
    "\n",
    "world_h = 5\n",
    "world_w = 5\n",
    "length = world_h * world_w\n",
    "gamma = 0.8\n",
    "state = [i for i in range(length)]  # 状态（编号）\n",
    "action = ['n', 'e', 's', 'w']  # 动作名称\n",
    "ds_action = {'n': -world_w, 'e': 1, 's': world_w, 'w': -1}\n",
    "value = [0 for i in range(length)]  # 初始化状态值函数，均为0.  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "def main():\n",
    "    max_iter = 7  # 最大迭代次数\n",
    "    initial_state()\n",
    "\n",
    "    iter = 1\n",
    "\n",
    "    while iter < max_iter:\n",
    "        numb = -1\n",
    "        for s in [20,21,22,23,24,15,16,17,18,19,10,11,12,13,14,5,6,7,8,9,0,1,2,3,4]:  # 遍历所有状态\n",
    "            numb += 1\n",
    "            value[s] = value_update(s,numb)  # 更新状态值函数\n",
    "            Caculate_Q(s,value,numb)\n",
    "        v = np.array(value).reshape(world_h, world_w)  # 更新状态值函数矩阵\n",
    "\n",
    "        if (iter <= 10) or (iter % 10 == 0):  # 前1次 + 每10次打印一次\n",
    "            print('k=', iter)  # 打印迭代次数\n",
    "            print(np.round(v, decimals=4))  # np.round() 返回浮点数的四舍五入值\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 汽车租赁问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;汽车租赁问题。杰克经营两家异地的汽车租赁场（A，B 租赁场），每天都会有客户来租车。如果每个租赁场有可供外租的汽车，每租出一辆汽车，杰克都会获得10美元的租金。为了保证每个租赁场有足够的车辆可租，每天晚上杰克会在两个租赁场之间移动车辆，每辆车的移车费用为2美元。假设每个租赁场的租车和还车的数量是一个泊松随机量，即期望数量n的概率为$\\frac{\\lambda_{n}}{n!}e^{-\\lambda}$，其中$\\lambda$分别是$\\lambda_{A1}=3$，$\\lambda_{B1}=4$，还车的$\\lambda$分别是$\\lambda_{A2}=3$，$\\lambda_{B2}=2$。<br>\n",
    "&emsp;&emsp;为了简化问题，给定3个假设：（1）任何一个租赁场车辆总数不超过20辆车；（2）当天还回的车辆第2天才能出租。（3）两个租车场之间每天最多可移车数量为5辆。<br>\n",
    "&emsp;&emsp;利用策略迭代方法，在折扣率$\\gamma = 0.9$时，计算两个租赁场点之间的最优移车策略。<br>\n",
    "&emsp;&emsp;将汽车租赁问题描述为一个持续的有限 MDP 模型。其中时刻 t 按天计算；状态为每天租还车结束时，两个租赁场的车辆数；动作为每天晚上在两个租赁场之间移动的车辆数目。<br>\n",
    "&emsp;&emsp;该问题的 MDP 模型为：<br>\n",
    "&emsp;&emsp;（1）状态空间：两个租赁场每天租还结束时，可供出租的车辆数组成的二维向量，状态共 $21*21=441$个，即$\\mathcal{S}={[0,0],[0,1],[0,2],...,[10,10],[10,11],....,[20,19][20,20]}$。用$s$表示状态空间中的某一个状态$[s_A,s_B]$。例如，$[3,5]$表示每天租还结束后，A 租赁场可供出租 3 辆车、B 租赁场可供出租 5 辆车的状态。<br>\n",
    "&emsp;&emsp;（2）动作空间：每天晚上在两个租赁场之间移动车辆的数目。根据任务的假设，可移动车辆数目不超过 5 辆。设 A 租赁场向 B 租赁场移车为“-”，B 租赁场向 A 租赁场移车为“ + ” 。 该 问 题 的 动 作 空 间 中 共 包 含 11 个 动 作 ， 即 ：$\\mathcal{A}(s)={-5,-4,-3,-2,-1,0,+1,+2,+3,+4,+5}$。用$a$表示动作空间中的某一个动作。例如，-2 表示 A 租赁场向 B 租赁场移车 2 辆；+3 表示 B 租赁场向 A 租赁场移车3辆。<br>\n",
    "&emsp;&emsp;（3）状态转移函数：\n",
    "&emsp;&emsp;令$s=[s_A,s_B]$，$s^{'}=s^{'}_A,s^{'}_B$，那么状态转移函数为：$p([s_A,s_B]),a,[s^{'}_A,s^{'}_B]$，即在当前状态$s=[s_A,s_B]$下，采取动作a，到达下一状态$s^{'}=s^{'}_A,s^{'}_B$的概率。设$n_A$为A租赁场当天租掉的车辆数；$n_B$为B租赁场当天租掉的车辆数。 $m_A$为A租赁场当天还回的车辆数；$m_B$为B租赁场当天还回的车辆数。假设当前状态为$s=[2,5]$，采取+1动作后，中间状态为$s_L=[3,4]$，当下一状态为$s^{'}=[1,2]$，对于 A 租赁场来说，一天的租掉、还回车辆$(n_A,m_A)$可能为：$(2,0)、(3,1)$共2种情况；对于B租赁场来说，一天的租掉、换回车辆$(n_B,m_B)$可能为：$(2,0)、(3,1)、(4,2)$共3种情况。那么在该情况下，状态转移函数$p([2,5],+1,[1,2])$计算为：\n",
    "\\begin{align}\n",
    "p([2,5],+1,[1,2]) &= \\left( \\frac{\\lambda_{A1}^2}{2!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{A1}^0}{0!}e^{-\\lambda ^{A1}}\\right)\n",
    "* \\left( \\frac{\\lambda_{B1}^2}{2!}e^{-\\lambda ^{B1}}\\right)* \\left( \\frac{\\lambda_{B1}^0}{0!}e^{-\\lambda ^{B1}}\\right) \\\\\n",
    " & + \\left( \\frac{\\lambda_{A1}^2}{2!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{A1}^0}{0!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{B1}^3}{3!}e^{-\\lambda ^{B1}}\\right)* \\left( \\frac{\\lambda_{B1}^1}{1!}e^{-\\lambda ^{B1}}\\right) \\\\\n",
    " & + \\left( \\frac{\\lambda_{A1}^2}{2!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{A1}^0}{0!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{B1}^4}{4!}e^{-\\lambda ^{B1}}\\right)* \\left( \\frac{\\lambda_{B1}^2}{2!}e^{-\\lambda ^{B1}}\\right) \\\\\n",
    " & + \\left( \\frac{\\lambda_{A1}^3}{3!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{A1}^1}{1!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{B1}^2}{2!}e^{-\\lambda ^{B1}}\\right)* \\left( \\frac{\\lambda_{B1}^0}{0!}e^{-\\lambda ^{B1}}\\right) \\\\\n",
    " & + \\left( \\frac{\\lambda_{A1}^3}{3!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{A1}^1}{1!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{B1}^3}{3!}e^{-\\lambda ^{B1}}\\right)* \\left( \\frac{\\lambda_{B1}^1}{1!}e^{-\\lambda ^{B1}}\\right) \\\\\n",
    " & + \\left( \\frac{\\lambda_{A1}^3}{3!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{A1}^1}{1!}e^{-\\lambda ^{A1}}\\right)* \\left( \\frac{\\lambda_{B1}^4}{4!}e^{-\\lambda ^{B1}}\\right)* \\left( \\frac{\\lambda_{B1}^2}{2!}e^{-\\lambda ^{B1}}\\right)\n",
    "\\end{align}\n",
    "根据任务可知，这里$\\lambda _{A1}=3,\\lambda _{B1}=4,\\lambda _{A2}=3,\\lambda _{B2}=2$。<br>\n",
    "综上所述，如果$0\\le S^{'}_A-S_A-a+n_A\\le 20$且$0\\le S^{'}_B-S_B-a+n_B\\le 20$，则有：<br><br>\n",
    "\\begin{align}\n",
    "p(s,a,s^{'})&= p([s_A,s_B],a,[s^{'}=s^{'}_A,s^{'}_B]) \\\\\n",
    "        &= \\sum _{n_A=0}^{s_A+a} \\sum _{n_B=0}^{s_B+a} \\left( \\frac{\\lambda_{A1}^{n_A}}{n_A!}e^{-\\lambda ^{A1}} \\right) * \\left( \\frac{\\lambda_{A2}^{S_A^{'}-S_A-a+n_A}}{(S_A^{'}-S_A-a+n_A)!}e^{-\\lambda ^{A2}} \\right)* \\left( \\frac{\\lambda_{B1}^{n_B}}{n_B!}e^{-\\lambda ^{B1}} \\right)* \\left( \\frac{\\lambda_{A2}^{S_B^{'}-S_B-a+n_B}}{(S_B^{'}-S_B-a+n_B)!}e^{-\\lambda ^{2}} \\right) \n",
    "\\end{align}\n",
    "&emsp;&emsp;（4）立即奖赏：该问题的立即奖赏函数为：$r([s_A,s_B],a,[s^{'}=s^{'}_A,s^{'}_B])$，即在当前状态$s=[s_A,s_B]$下，采取动作 a，到达下一状态$s_{'}=[s^{'}=s^{'}_A,s^{'}_B]$得到的立即奖赏。<br>\n",
    "&emsp;&emsp;（5）折扣因子：$\\gamma=0.9$。<br>\n",
    "&emsp;&emsp;该问题需要从一个确定策略出发进行策略迭代。本实验的初始策略为：在任何状态下，不考虑两个租赁场的需求，选择不移动车辆（动作为 0）。然后进行策略评估，并根据值函数进行策略改进。如此反复，直到策略收敛，找到最优策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max value change 196.62783361783852\n",
      "max value change 134.98823859766583\n",
      "max value change 91.41415360228919\n",
      "max value change 67.17097732555729\n",
      "max value change 51.29055484635097\n",
      "max value change 38.49091000659837\n",
      "max value change 29.406139835126424\n",
      "max value change 25.7210573245398\n",
      "max value change 22.381602293031023\n",
      "max value change 19.40385808254939\n",
      "max value change 16.77577350573091\n",
      "max value change 14.47251552455765\n",
      "max value change 12.464101852186843\n",
      "max value change 10.719367983418692\n",
      "max value change 9.20806226246873\n",
      "max value change 7.9019189666795455\n",
      "max value change 6.775146571130392\n",
      "max value change 5.8045764710083745\n",
      "max value change 4.969618520007145\n",
      "max value change 4.252112693842776\n",
      "max value change 3.6361309524054946\n",
      "max value change 3.107761240497666\n",
      "max value change 2.654891834022692\n",
      "max value change 2.26700589940549\n",
      "max value change 1.9349911763441128\n",
      "max value change 1.650966802154585\n",
      "max value change 1.4081276418079938\n",
      "max value change 1.2006055672075036\n",
      "max value change 1.02334664187498\n",
      "max value change 0.8720029351049448\n",
      "max value change 0.7428376083516355\n",
      "max value change 0.6326419232035505\n",
      "max value change 0.5386628774742235\n",
      "max value change 0.45854026040933604\n",
      "max value change 0.3902520158000584\n",
      "max value change 0.33206690395809346\n",
      "max value change 0.28250355471067223\n",
      "max value change 0.2402951004837064\n",
      "max value change 0.20435866938208846\n",
      "max value change 0.1737691018435612\n",
      "max value change 0.14773633074884174\n",
      "max value change 0.12558593365213255\n",
      "max value change 0.10674242749371388\n",
      "max value change 0.09071493100810812\n",
      "max value change 0.07708486873008269\n",
      "max value change 0.06549543334426744\n",
      "max value change 0.05564256088280217\n",
      "max value change 0.047267206266042194\n",
      "max value change 0.040148735572074656\n",
      "max value change 0.03409927655258116\n",
      "max value change 0.028958890796900505\n",
      "max value change 0.02459144993093787\n",
      "max value change 0.02088111467702447\n",
      "max value change 0.01772932984539466\n",
      "max value change 0.0150522606048753\n",
      "max value change 0.012778605996800252\n",
      "max value change 0.010847734796413988\n",
      "max value change 0.00920809667559297\n",
      "max value change 0.007815868406908066\n",
      "max value change 0.006633800647819044\n",
      "max value change 0.005630235829983121\n",
      "max value change 0.0047782719802853535\n",
      "max value change 0.004055050928627679\n",
      "max value change 0.003441152547054571\n",
      "max value change 0.002920079317334512\n",
      "max value change 0.0024778178350288727\n",
      "max value change 0.0021024658457236\n",
      "max value change 0.0017839150607983356\n",
      "max value change 0.0015135814573454809\n",
      "max value change 0.0012841759864272717\n",
      "max value change 0.0010895096651211134\n",
      "max value change 0.0009243279118891223\n",
      "max value change 0.0007841697620847299\n",
      "max value change 0.000665248240920846\n",
      "max value change 0.0005643487139082026\n",
      "max value change 0.00047874254232738167\n",
      "max value change 0.00040611372588728045\n",
      "max value change 0.0003444966009737982\n",
      "max value change 0.000292222921245866\n",
      "max value change 0.0002478769196159192\n",
      "max value change 0.00021025715051337102\n",
      "max value change 0.00017834408060934948\n",
      "max value change 0.00015127258103575514\n",
      "max value change 0.00012830856951495662\n",
      "max value change 0.00010882917825938421\n",
      "max value change 9.230592559106299e-05\n",
      "policy stable False\n",
      "max value change 55.19093908880404\n",
      "max value change 30.461811005479547\n",
      "max value change 9.480839880848066\n",
      "max value change 2.15505969633125\n",
      "max value change 0.8886987018684636\n",
      "max value change 0.7499174770809987\n",
      "max value change 0.639286337655335\n",
      "max value change 0.5408817743817167\n",
      "max value change 0.45625283430945274\n",
      "max value change 0.3843744360444816\n",
      "max value change 0.3236341287950495\n",
      "max value change 0.2724188356532409\n",
      "max value change 0.22927836106435961\n",
      "max value change 0.1929570235217284\n",
      "max value change 0.16238414104213916\n",
      "max value change 0.1366529788035109\n",
      "max value change 0.11499809006511441\n",
      "max value change 0.09677429997344689\n",
      "max value change 0.08143822742709972\n",
      "max value change 0.06853240444064568\n",
      "max value change 0.05767177113210664\n",
      "max value change 0.04853224973317083\n",
      "max value change 0.04084110238153471\n",
      "max value change 0.0343688049685511\n",
      "max value change 0.028922203370598254\n",
      "max value change 0.024338751800883074\n",
      "max value change 0.020481663106181713\n",
      "max value change 0.017235827113609048\n",
      "max value change 0.014504375578610507\n",
      "max value change 0.012205791382768894\n",
      "max value change 0.010271475813169673\n",
      "max value change 0.008643701332857745\n",
      "max value change 0.00727388878038937\n",
      "max value change 0.006121157584175307\n",
      "max value change 0.005151105727975391\n",
      "max value change 0.004334783062063252\n",
      "max value change 0.003647827318388863\n",
      "max value change 0.0030697370434609184\n",
      "max value change 0.002583259759376233\n",
      "max value change 0.0021738770736305923\n",
      "max value change 0.0018293714041419662\n",
      "max value change 0.001539461349409521\n",
      "max value change 0.001295494857288304\n",
      "max value change 0.001090191011655861\n",
      "max value change 0.0009174227399171286\n",
      "max value change 0.0007720339602315107\n",
      "max value change 0.0006496857000115597\n",
      "max value change 0.0005467266093432954\n",
      "max value change 0.00046008398362573644\n",
      "max value change 0.00038717206842875385\n",
      "max value change 0.0003258148859117682\n",
      "max value change 0.0002741812967315127\n",
      "max value change 0.00023073035316656387\n",
      "max value change 0.00019416530710714142\n",
      "max value change 0.00016339491486405677\n",
      "max value change 0.00013750086839081632\n",
      "max value change 0.00011571038652391508\n",
      "max value change 9.737315667734947e-05\n",
      "policy stable False\n",
      "max value change 4.673522696574878\n",
      "max value change 3.1907732369808173\n",
      "max value change 2.157401984847297\n",
      "max value change 1.5496717413702754\n",
      "max value change 1.0478630509624054\n",
      "max value change 0.6613820528865517\n",
      "max value change 0.4009349446013175\n",
      "max value change 0.24067473679929208\n",
      "max value change 0.1465908481925453\n",
      "max value change 0.10094884629097578\n",
      "max value change 0.07817597525740894\n",
      "max value change 0.06622858112274344\n",
      "max value change 0.056070364851734666\n",
      "max value change 0.047453637927617365\n",
      "max value change 0.04015355040701252\n",
      "max value change 0.033973018442281955\n",
      "max value change 0.02874221274765887\n",
      "max value change 0.024316051463756594\n",
      "max value change 0.02057115327647807\n",
      "max value change 0.017402843425429637\n",
      "max value change 0.014722432165171995\n",
      "max value change 0.012454826319071799\n",
      "max value change 0.01053646919183393\n",
      "max value change 0.008913579528893933\n",
      "max value change 0.007540653259752617\n",
      "max value change 0.006379192071108264\n",
      "max value change 0.00539662596497692\n",
      "max value change 0.004565400907665662\n",
      "max value change 0.003862206601922935\n",
      "max value change 0.0032673230069235615\n",
      "max value change 0.0027640674284157285\n",
      "max value change 0.002338326717676864\n",
      "max value change 0.001978161514216481\n",
      "max value change 0.0016734714347421686\n",
      "max value change 0.0014157118207549502\n",
      "max value change 0.0011976541187550538\n",
      "max value change 0.0010131831683679593\n",
      "max value change 0.0008571257059202253\n",
      "max value change 0.0007251052909964528\n",
      "max value change 0.0006134195709250889\n",
      "max value change 0.0005189364557054432\n",
      "max value change 0.0004390062826473695\n",
      "max value change 0.00037138750536769294\n",
      "max value change 0.0003141838392934915\n",
      "max value change 0.00026579107696989013\n",
      "max value change 0.00022485210081413243\n",
      "max value change 0.00019021882934566747\n",
      "max value change 0.000160920012092447\n",
      "max value change 0.00013613400159329103\n",
      "max value change 0.00011516570390313063\n",
      "max value change 9.742708721205418e-05\n",
      "policy stable False\n",
      "max value change 0.8061278615540459\n",
      "max value change 0.302438825859781\n",
      "max value change 0.15006583567969756\n",
      "max value change 0.09206975900929137\n",
      "max value change 0.062352869819847\n",
      "max value change 0.04151017865012818\n",
      "max value change 0.024803031552551147\n",
      "max value change 0.01388039218090853\n",
      "max value change 0.007446941734883694\n",
      "max value change 0.003889778655434384\n",
      "max value change 0.0020028945082231076\n",
      "max value change 0.00102770300929933\n",
      "max value change 0.0005315442502933365\n",
      "max value change 0.00028100155066113075\n",
      "max value change 0.00015442810911281413\n",
      "max value change 8.988017270894488e-05\n",
      "policy stable False\n",
      "max value change 0.0699998805538371\n",
      "max value change 0.014806994613309143\n",
      "max value change 0.006899995248772939\n",
      "max value change 0.004167032993905195\n",
      "max value change 0.0026703592358217065\n",
      "max value change 0.001547114834011154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max value change 0.0008482386133437103\n",
      "max value change 0.00044346004142425954\n",
      "max value change 0.00022586233239962894\n",
      "max value change 0.00011383611263227067\n",
      "max value change 5.771942301180388e-05\n",
      "policy stable True\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import poisson\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #显示中文标签\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# maximum # of cars in each location\n",
    "MAX_CARS = 20\n",
    "\n",
    "# maximum # of cars to move during night\n",
    "MAX_MOVE_OF_CARS = 5\n",
    "\n",
    "# expectation for rental requests in first location\n",
    "RENTAL_REQUEST_FIRST_LOC = 3\n",
    "\n",
    "# expectation for rental requests in second location\n",
    "RENTAL_REQUEST_SECOND_LOC = 4\n",
    "\n",
    "# expectation for # of cars returned in first location\n",
    "RETURNS_FIRST_LOC = 3\n",
    "\n",
    "# expectation for # of cars returned in second location\n",
    "RETURNS_SECOND_LOC = 2\n",
    "\n",
    "DISCOUNT = 0.9\n",
    "\n",
    "# credit earned by a car\n",
    "RENTAL_CREDIT = 10\n",
    "\n",
    "# cost of moving a car\n",
    "MOVE_CAR_COST = 2\n",
    "\n",
    "# all possible actions\n",
    "actions = np.arange(-MAX_MOVE_OF_CARS, MAX_MOVE_OF_CARS + 1)\n",
    "\n",
    "# An up bound for poisson distribution\n",
    "# If n is greater than this value, then the probability of getting n is truncated to 0\n",
    "POISSON_UPPER_BOUND = 11\n",
    "\n",
    "# Probability for poisson distribution\n",
    "# @lam: lambda should be less than 10 for this function\n",
    "poisson_cache = dict()\n",
    "\n",
    "\n",
    "def poisson_probability(n, lam):\n",
    "    global poisson_cache\n",
    "    key = n * 10 + lam\n",
    "    if key not in poisson_cache:\n",
    "        poisson_cache[key] = poisson.pmf(n, lam)\n",
    "    return poisson_cache[key]\n",
    "\n",
    "\n",
    "def expected_return(state, action, state_value, constant_returned_cars):\n",
    "    \"\"\"\n",
    "    @state: [# of cars in first location, # of cars in second location]\n",
    "    @action: positive if moving cars from first location to second location,\n",
    "            negative if moving cars from second location to first location\n",
    "    @stateValue: state value matrix\n",
    "    @constant_returned_cars:  if set True, model is simplified such that\n",
    "    the # of cars returned in daytime becomes constant\n",
    "    rather than a random value from poisson distribution, which will reduce calculation time\n",
    "    and leave the optimal policy/value state matrix almost the same\n",
    "    \"\"\"\n",
    "    # initailize total return\n",
    "    returns = 0.0\n",
    "\n",
    "    # cost for moving cars\n",
    "    returns -= MOVE_CAR_COST * abs(action)\n",
    "\n",
    "    # moving cars\n",
    "    NUM_OF_CARS_FIRST_LOC = min(state[0] + action, MAX_CARS)\n",
    "    NUM_OF_CARS_SECOND_LOC = min(state[1] - action, MAX_CARS)\n",
    "\n",
    "    # go through all possible rental requests\n",
    "    for rental_request_first_loc in range(POISSON_UPPER_BOUND):\n",
    "        for rental_request_second_loc in range(POISSON_UPPER_BOUND):\n",
    "            # probability for current combination of rental requests\n",
    "            prob = poisson_probability(rental_request_first_loc, RENTAL_REQUEST_FIRST_LOC) * \\\n",
    "                poisson_probability(rental_request_second_loc, RENTAL_REQUEST_SECOND_LOC)\n",
    "\n",
    "            num_of_cars_first_loc = NUM_OF_CARS_FIRST_LOC\n",
    "            num_of_cars_second_loc = NUM_OF_CARS_SECOND_LOC\n",
    "\n",
    "            # valid rental requests should be less than actual # of cars\n",
    "            valid_rental_first_loc = min(num_of_cars_first_loc, rental_request_first_loc)\n",
    "            valid_rental_second_loc = min(num_of_cars_second_loc, rental_request_second_loc)\n",
    "\n",
    "            # get credits for renting\n",
    "            reward = (valid_rental_first_loc + valid_rental_second_loc) * RENTAL_CREDIT\n",
    "            num_of_cars_first_loc -= valid_rental_first_loc\n",
    "            num_of_cars_second_loc -= valid_rental_second_loc\n",
    "\n",
    "            if constant_returned_cars:\n",
    "                # get returned cars, those cars can be used for renting tomorrow\n",
    "                returned_cars_first_loc = RETURNS_FIRST_LOC\n",
    "                returned_cars_second_loc = RETURNS_SECOND_LOC\n",
    "                num_of_cars_first_loc = min(num_of_cars_first_loc + returned_cars_first_loc, MAX_CARS)\n",
    "                num_of_cars_second_loc = min(num_of_cars_second_loc + returned_cars_second_loc, MAX_CARS)\n",
    "                returns += prob * (reward + DISCOUNT * state_value[num_of_cars_first_loc, num_of_cars_second_loc])\n",
    "            else:\n",
    "                for returned_cars_first_loc in range(POISSON_UPPER_BOUND):\n",
    "                    for returned_cars_second_loc in range(POISSON_UPPER_BOUND):\n",
    "                        prob_return = poisson_probability(\n",
    "                            returned_cars_first_loc, RETURNS_FIRST_LOC) * poisson_probability(returned_cars_second_loc, RETURNS_SECOND_LOC)\n",
    "                        num_of_cars_first_loc_ = min(num_of_cars_first_loc + returned_cars_first_loc, MAX_CARS)\n",
    "                        num_of_cars_second_loc_ = min(num_of_cars_second_loc + returned_cars_second_loc, MAX_CARS)\n",
    "                        prob_ = prob_return * prob\n",
    "                        returns += prob_ * (reward + DISCOUNT *\n",
    "                                            state_value[num_of_cars_first_loc_, num_of_cars_second_loc_])\n",
    "    return returns\n",
    "\n",
    "\n",
    "def render_car(constant_returned_cars=True):\n",
    "    value = np.zeros((MAX_CARS + 1, MAX_CARS + 1))\n",
    "    policy = np.zeros(value.shape, dtype=np.int)\n",
    "\n",
    "    iterations = 0\n",
    "    _, axes = plt.subplots(2, 3, figsize=(40, 20))\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']  # 显示中文标签\n",
    "    axes = axes.flatten()\n",
    "    while True:\n",
    "        fig = sns.heatmap(np.flipud(policy), cmap=\"YlGnBu\", ax=axes[iterations])\n",
    "        fig.set_ylabel('# cars at first location', fontsize=30)\n",
    "        fig.set_yticks(list(reversed(range(MAX_CARS + 1))))\n",
    "        fig.set_xlabel('# cars at second location', fontsize=30)\n",
    "        fig.set_title('policy {}'.format(iterations), fontsize=30)\n",
    "\n",
    "        # policy evaluation (in-place)\n",
    "        while True:\n",
    "            old_value = value.copy()\n",
    "            for i in range(MAX_CARS + 1):\n",
    "                for j in range(MAX_CARS + 1):\n",
    "                    new_state_value = expected_return([i, j], policy[i, j], value, constant_returned_cars)\n",
    "                    value[i, j] = new_state_value\n",
    "            max_value_change = abs(old_value - value).max()\n",
    "            print('max value change {}'.format(max_value_change))\n",
    "            if max_value_change < 1e-4:\n",
    "                break\n",
    "\n",
    "        # policy improvement\n",
    "        policy_stable = True\n",
    "        for i in range(MAX_CARS + 1):\n",
    "            for j in range(MAX_CARS + 1):\n",
    "                old_action = policy[i, j]\n",
    "                action_returns = []\n",
    "                for action in actions:\n",
    "                    if (0 <= action <= i) or (-j <= action <= 0):\n",
    "                        action_returns.append(expected_return([i, j], action, value, constant_returned_cars))\n",
    "                    else:\n",
    "                        action_returns.append(-np.inf)\n",
    "                new_action = actions[np.argmax(action_returns)]\n",
    "                policy[i, j] = new_action\n",
    "                if policy_stable and old_action != new_action:\n",
    "                    policy_stable = False\n",
    "        print('policy stable {}'.format(policy_stable))\n",
    "\n",
    "        if policy_stable:\n",
    "            break\n",
    "\n",
    "        iterations += 1\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    render_car()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在环境已知的前提下，基于马尔可夫决策过程，动态规划可以很好的完成强化学习任务。策略评估通常对于给定的策略，不断迭代计算每个状态（或状态-动作对）的价值。其迭代方法主要是利用对后继状态（或状态-动作对）价值的估计，来更新当前状态（或状态-动作对）价值的估计，也就是用自举的方法。策略改进是采用贪心算法，利用动作值函数获得更优的策略，每次都选择最好的动作。策略迭代是重复策略评估和策略改进的迭代，直到策略\n",
    "收敛，找到最优的策略。但是策略迭代需要多次使用策略评估才能得到收敛的状态（或状态-动作对）值函数，即策略评估是迭代进行的，只有在$v_\\pi$收敛时，才能停止迭代。值迭代无需等到其完全收敛，提早的计算出贪心策略，截断策略评估，在一次遍历后即刻停止策略评估，并对每个状态进行更新。实践证明，值迭代算法收敛速度优于策略迭代算法。广义策略迭代则体现了策略评估与策略改进交替进行的一般性。在GPI中，策略评估和策略改进同时进行，只要这两个过程都能不断地更新，就能收敛到最优值函数和最优策略。从这一角度看，值迭代也属于GPI，而实际上几乎所有的强化学习方法都可以被描述为 GPI。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
